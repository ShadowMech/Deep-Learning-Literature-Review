% This file was created with JabRef 2.7.1.
% Encoding: UTF8

@ARTICLE{Arel2010,
  author = {Arel, Itamar and Rose, DC and Karnowski, TP},
  title = {{Deep machine learning-a new frontier in artificial intelligence
	research}},
  journal = {Comput. Intell. \ldots},
  year = {2010},
  pages = {13--18},
  number = {November},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Arel, Rose, Karnowski_2010_Deep machine learning-a new frontier in artificial intelligence research.pdf:pdf},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5605630}
}

@ARTICLE{Arel2010a,
  author = {Arel, I and Rose, D C and Karnowski, T P},
  title = {{Deep Machine Learning - A New Frontier in Artificial Intelligence
	Research [Research Frontier]}},
  journal = {IEEE Comput. Intell. Mag.},
  year = {2010},
  volume = {5},
  pages = {13--18},
  number = {4},
  month = {\#nov\#},
  abstract = {Mimicking the efficiency and robustness by which the human brain represents
	information has been a core challenge in artificial intelligence
	research for decades. Humans are exposed to myriad of sensory data
	received every second of the day and are somehow able to capture
	critical aspects of this data in a way that allows for its future
	use in a concise manner. Over 50 years ago, Richard Bellman, who
	introduced dynamic programming theory and pioneered the field of
	optimal control, asserted that high dimensionality of data is a fundamental
	hurdle in many science and engineering applications. The main difficulty
	that arises, particularly in the context of pattern classification
	applications, is that the learning complexity grows exponentially
	with linear increase in the dimensionality of the data. He coined
	this phenomenon the curse of dimensionality [1]. The mainstream approach
	of overcoming the curse has been to pre-process the data in a manner
	that would reduce its dimensionality to that which can be effectively
	processed, for example by a classification engine. This dimensionality
	reduction scheme is often referred to as feature extraction. As a
	result, it can be argued that the intelligence behind many pattern
	recognition systems has shifted to the human-engineered feature extraction
	process, which at times can be challenging and highly application-dependent
	[2]. Moreover, if incomplete or erroneous features are extracted,
	the classification process is inherently limited in performance.
	© 2006 IEEE.},
  doi = {10.1109/MCI.2010.938364},
  issn = {1556-603X},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77958488310&partnerID=tZOtx3y1}
}

@ARTICLE{Bengio2013,
  author = {Bengio, Yoshua},
  title = {{Deep Learning of Representations: Looking Forward}},
  year = {2013},
  month = {\#may\#},
  abstract = {Deep learning research aims at discovering learning algorithms that
	discover multiple levels of distributed representations, with higher
	levels representing more abstract concepts. Although the study of
	deep learning has already led to impressive theoretical results,
	learning algorithms and breakthrough experiments, several challenges
	lie ahead. This paper proposes to examine some of these challenges,
	centering on the questions of scaling deep learning algorithms to
	much larger models and datasets, reducing optimization difficulties
	due to ill-conditioning or local minima, designing more efficient
	and powerful inference and sampling procedures, and learning to disentangle
	the factors of variation underlying the observed data. It also proposes
	a few forward-looking research directions aimed at overcoming these
	challenges.},
  archiveprefix = {arXiv},
  arxivid = {1305.0445},
  eprint = {1305.0445},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2013_Deep Learning of Representations Looking Forward.pdf:pdf},
  url = {http://arxiv.org/abs/1305.0445}
}

@ARTICLE{Bengio2009,
  author = {Bengio, Yoshua},
  title = {{Learning deep architectures for AI}},
  journal = {Found. trends® Mach. Learn.},
  year = {2009},
  volume = {2},
  pages = {1--127},
  number = {1},
  abstract = {Theoretical results suggest that in order to learn the kind of complicated
	functions that can represent high-level abstractions (e.g., in vision,
	language, and other AI-level tasks), one may need deep architectures.
	Deep architectures are composed of multiple levels of non-linear
	operations, such as in neural nets with many hidden layers or in
	complicated propositional formulae re-using many sub-formulae. Searching
	the parameter space of deep architectures is a difficult task, but
	learning algorithms such as those for Deep Belief Networks have recently
	been proposed to tackle this problem with notable success, beating
	the stateof-the-art in certain areas. This monograph discusses the
	motivations and principles regarding learning algorithms for deep
	architectures, in particular those exploiting as building blocks
	unsupervised learning of single-layer models such as Restricted Boltzmann
	Machines, used to construct deeper models such as Deep Belief Networks.
	© 2009 Y. Bengio.},
  doi = {10.1561/2200000006},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2009_Learning deep architectures for AI.pdf:pdf},
  issn = {1935-8237},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-69349090197&partnerID=tZOtx3y1 http://dl.acm.org/citation.cfm?id=1658424}
}

@ARTICLE{Bengio2013a,
  author = {Bengio, Y and Courville, A},
  title = {{Deep learning of representations}},
  journal = {Handb. Neural Inf. Process.},
  year = {2013},
  volume = {49},
  pages = {1--28},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, Courville_2013_Deep learning of representations.pdf:pdf},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-36657-4_1}
}

@ARTICLE{Bengio2012,
  author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  title = {{Representation learning: a review and new perspectives.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2013},
  volume = {35},
  pages = {1798--828},
  number = {1993},
  month = {\#jun\#},
  abstract = {The success of machine learning algorithms generally depends on data
	representation, and we hypothesize that this is because different
	representations can entangle and hide more or less the different
	explanatory factors of variation behind the data. Although specific
	domain knowledge can be used to help design representations, learning
	with generic priors can also be used, and the quest for AI is motivating
	the design of more powerful representation-learning algorithms implementing
	such priors. This paper reviews recent work in the area of unsupervised
	feature learning and deep learning, covering advances in probabilistic
	models, autoencoders, manifold learning, and deep networks. This
	motivates longer term unanswered questions about the appropriate
	objectives for learning good representations, for computing representations
	(i.e., inference), and the geometrical connections between representation
	learning, density estimation, and manifold learning.},
  archiveprefix = {arXiv},
  arxivid = {1206.5538},
  doi = {10.1109/TPAMI.2013.50},
  eprint = {1206.5538},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Bengio, Courville, Vincent_2013_Representation learning a review and new perspectives.pdf:pdf},
  issn = {1939-3539},
  keywords = {Algorithms,Artificial Intelligence,Artificial Intelligence: trends,Humans,Neural
	Networks (Computer)},
  pmid = {23787338},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879854889&partnerID=tZOtx3y1 http://www.ncbi.nlm.nih.gov/pubmed/23787338 http://arxiv.org/abs/1206.5538}
}

@ARTICLE{Bengio2007,
  author = {Bengio, Yoshua and LeCun, Y},
  title = {{Scaling learning algorithms towards AI}},
  journal = {Large-scale kernel Mach.},
  year = {2007},
  pages = {1--41},
  number = {1},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, LeCun_2007_Scaling learning algorithms towards AI.pdf:pdf},
  url = {http://www.iro.umontreal.ca/$\sim$lisa/bib/pub_subject/language/pointeurs/bengio+lecun-chapter2007.pdf}
}

@ARTICLE{Bergstra2006,
  author = {Bergstra, James and Casagrande, Norman and Erhan, Dumitru and Eck,
	Douglas and K\'{e}gl, Bal\'{a}zs},
  title = {{Aggregate features and ADABOOST for music classification}},
  journal = {Mach. Learn.},
  year = {2006},
  volume = {65},
  pages = {473--484},
  number = {2-3},
  month = {\#jun\#},
  abstract = {We present an algorithm that predicts musical genre and artist from
	an audio waveform. Our method uses the ensemble learner ADABOOST
	to select from a set of audio features that have been extracted from
	segmented audio and then aggregated. Our classifier proved to be
	the most effective method for genre classification at the recent
	MIREX 2005 international contests in music information extraction,
	and the second-best method for recognizing artists. This paper describes
	our method in detail, from feature extraction to song classification,
	and presents an evaluation of our method on three genre databases
	and two artist-recognition databases. Furthermore, we present evidence
	collected from a variety of popular features and classifiers that
	the technique of classifying features aggregated over segments of
	audio is better than classifying either entire songs or individual
	short-timescale features. © Springer Science + Business Media, LLC
	2006.},
  doi = {10.1007/s10994-006-9019-7},
  issn = {0885-6125},
  keywords = {Artist recognition,Audio feature aggregation,Genre classification,MIREX,Multiclass
	ADABOOST},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33751531805&partnerID=tZOtx3y1}
}

@BOOK{Bertin-Mahieux2011,
  title = {{Machine Audition}},
  publisher = {IGI Global},
  year = {2011},
  editor = {Wang, Wenwu},
  author = {Bertin-Mahieux, Thierry and Eck, Douglas and Mandel, Michael},
  pages = {334--352},
  abstract = {Recently there has been a great deal of attention paid to the automatic
	prediction of tags for music and audio in general. Social tags are
	user-generated keywords associated with some resource on the Web.
	In the case of music, social tags have become an important component
	of "Web 2.0" recommender systems. There have been many attempts at
	automatically applying tags to audio for different purposes: database
	management, music recommendation, improved human-computer interfaces,
	estimating similarity among songs, and so on. Many published results
	show that this problem can be tackled using machine learning techniques,
	however, no method so far has been proven to be particularly suited
	to the task. First, it seems that no one has yet found an appropriate
	algorithm to solve this challenge. But second, the task definition
	itself is problematic. In an effort to better understand the task
	and also to help new researchers bring their insights to bear on
	this problem, this chapter provides a review of the state-of-the-art
	methods for addressing automatic tagging of audio. It is divided
	in the following sections: goal, framework, audio representation,
	labeled data, classification, evaluation, and future directions.
	Such a division helps understand the commonalities and strengths
	of the different methods that have been proposed. © 2011, IGI Global.},
  booktitle = {Mach. Audit. Princ. Algorithms Syst.},
  doi = {10.4018/978-1-61520-919-4},
  isbn = {9781615209194},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80051647410&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Black2007,
  author = {Black, Alan W and Zen, Heiga and Tokuda, Keiichi},
  title = {{Statistical Parametric Speech Synthesis}},
  booktitle = {2007 IEEE Int. Conf. Acoust. Speech Signal Process. - ICASSP '07},
  year = {2007},
  volume = {4},
  pages = {IV--1229--IV--1232},
  publisher = {IEEE},
  abstract = {This paper gives a general overview of techniques in statistical parametric
	speech synthesis. One of the instances of these techniques, called
	HMM-based generation synthesis (or simply HMM-based synthesis), has
	recently been shown to be very effective in generating acceptable
	speech synthesis. This paper also contrasts these techniques with
	the more conventional unit selection technology that has dominated
	speech synthesis over the last ten years. Advantages and disadvantages
	of statistical parametric synthesis are highlighted as well as identifying
	where we expect the key developments to appear in the immediate future.
	© 2007 IEEE.},
  doi = {10.1109/ICASSP.2007.367298},
  isbn = {1-4244-0727-3},
  issn = {15206149},
  keywords = {Hidden Markov models,Speech synthesis},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34547526960&partnerID=tZOtx3y1}
}

@ARTICLE{Blei2010,
  author = {Blei, David M. and Griffiths, Thomas L. and Jordan, Michael I.},
  title = {{The nested chinese restaurant process and bayesian nonparametric
	inference of topic hierarchies}},
  journal = {J. ACM},
  year = {2010},
  volume = {57},
  pages = {1--30},
  number = {2},
  month = {\#jan\#},
  abstract = {We present the nested Chinese restaurant process (nCRP), a stochastic
	process that assigns probability distributions to ensembles of infinitely
	deep, infinitely branching trees. We show how this stochastic process
	can be used as a prior distribution in a Bayesian nonparametric model
	of document collections. Specifically, we present an application
	to information retrieval in which documents are modeled as paths
	down a random tree, and the preferential attachment dynamics of the
	nCRP leads to clustering of documents according to sharing of topics
	at multiple levels of abstraction. Given a corpus of documents, a
	posterior inference algorithm finds an approximation to a posterior
	distribution over trees, topics and allocations of words to levels
	of the tree. We demonstrate this algorithm on collections of scientific
	abstracts from several journals. This model exemplifies a recent
	trend in statistical machine learningthe use of Bayesian nonparametric
	methods to infer distributions on flexible data structures. © 2010
	ACM.},
  doi = {10.1145/1667053.1667056},
  issn = {00045411},
  keywords = {Bayesian nonparametric statistics,Unsupervised learning},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-76849117578&partnerID=tZOtx3y1}
}

@ARTICLE{Boser1992,
  author = {Boser, BE and Guyon, IM and Vapnik, VN},
  title = {{A training algorithm for optimal margin classifiers}},
  journal = {\ldots fifth Annu. Work. \ldots},
  year = {1992},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boser, Guyon, Vapnik_1992_A training algorithm for optimal margin classifiers.pdf:pdf},
  url = {http://dl.acm.org/citation.cfm?id=130401}
}

@ARTICLE{Bottou1992,
  author = {Bottou, L and Vapnik, V},
  title = {{Local learning algorithms}},
  journal = {Neural Comput.},
  year = {1992},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bottou, Vapnik_1992_Local learning algorithms.pdf:pdf},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.6.888}
}

@INPROCEEDINGS{Boureau2010,
  author = {Boureau, Y-Lan and Bach, Francis and LeCun, Yann and Ponce, Jean},
  title = {{Learning mid-level features for recognition}},
  booktitle = {2010 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
  year = {2010},
  pages = {2559--2566},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {Many successful models for scene or object recognition transform low-level
	descriptors (such as Gabor filter responses, or SIFT descriptors)
	into richer representations of intermediate complexity. This process
	can often be broken down into two steps: (1) a coding step, which
	performs a pointwise transformation of the descriptors into a representation
	better adapted to the task, and (2) a pooling step, which summarizes
	the coded features over larger neighborhoods. Several combinations
	of coding and pooling schemes have been proposed in the literature.
	The goal of this paper is threefold. We seek to establish the relative
	importance of each step of mid-level feature extraction through a
	comprehensive cross evaluation of several types of coding modules
	(hard and soft vector quantization, sparse coding) and pooling schemes
	(by taking the average, or the maximum), which obtains state-of-the-art
	performance or better on several recognition benchmarks. We show
	how to improve the best performing coding scheme by learning a supervised
	discriminative dictionary for sparse coding. We provide theoretical
	and empirical insight into the remarkable performance of max pooling.
	By teasing apart components shared by modern mid-level feature extractors,
	our approach aims to facilitate the design of better recognition
	architectures.},
  doi = {10.1109/CVPR.2010.5539963},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boureau et al._2010_Learning mid-level features for recognition.pdf:pdf},
  isbn = {978-1-4244-6984-0},
  issn = {1063-6919},
  keywords = {Convolutional codes,Dictionaries,Feature extraction,Gabor filter responses,Gabor
	filters,Image classification,Image coding,Image representation,Layout,Object
	recognition,SIFT descriptors,Vector quantization,coding step,feature
	extraction,learning (artificial intelligence),low level descriptors,mid
	level features learning,object recognition,pointwise transformation,pooling
	step,sparse coding,vector quantisation,vector quantization},
  shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539963}
}

@ARTICLE{Castrodad2012,
  author = {Castrodad, Alexey and Sapiro, Guillermo},
  title = {{Sparse Modeling of Human Actions from Motion Imagery}},
  journal = {Int. J. Comput. Vis.},
  year = {2012},
  volume = {100},
  pages = {1--15},
  number = {1},
  month = {\#jun\#},
  abstract = {An efficient sparse modeling pipeline for the classification of human
	actions from video is here developed. Spatio-temporal features that
	characterize local changes in the image are first extracted. This
	is followed by the learning of a class-structured dictionary encoding
	the individual actions of interest. Classification is then based
	on reconstruction, where the label assigned to each video comes from
	the optimal sparse linear combination of the learned basis vectors
	(action primitives) representing the actions. A low computational
	cost deep-layer model learning the inter-class correlations of the
	data is added for increasing discriminative power. In spite of its
	simplicity and low computational cost, the method outperforms previously
	reported results for virtually all standard datasets. © 2012 Springer
	Science+Business Media, LLC (outside the USA).},
  doi = {10.1007/s11263-012-0534-7},
  issn = {0920-5691},
  keywords = {Action classification,Dictionary learning,Sparse modeling,Supervised
	learning},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861728486&partnerID=tZOtx3y1}
}

@ARTICLE{Chen2014,
  author = {Chen, X and Lin, X},
  title = {{Big Data Deep Learning: Challenges and Perspectives}},
  year = {2014},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Chen, Lin_2014_Big Data Deep Learning Challenges and Perspectives.pdf:pdf},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6817512}
}

@ARTICLE{Chi1994,
  author = {Chi, M},
  title = {{Eliciting self-explanations improves understanding}},
  journal = {Cogn. Sci.},
  year = {1994},
  volume = {18},
  pages = {439--477},
  number = {3},
  month = {\#sep\#},
  abstract = {Learning involves the integration of new information into existing
	knowledge. Generating explanations to oneself (self-explaining) facilitates
	that integration process. Previously, self-explanation has been shown
	to improve the acquisition of problem-solving skills when studying
	worked-out examples. This study extends that finding, showing that
	self-explanation can also be facilitative when it is explicitly promoted,
	in the context of learning declarative knowledge from an expository
	text. Without any extensive training, 14 eighth-grade students were
	merely asked to self-explain after reading each line of a passage
	on the human circulatory system. Ten students in the control group
	read the same text twice, but were not prompted to self-explain.
	All of the students were tested for their circulatory system knowledge
	before and after reading the text. The prompted group had a greater
	gain from the pretest to the posttest. Moreover, prompted students
	who generated a large number of self-explanations (the high explainers)
	learned with greater understanding than low explainers. Understanding
	was assessed by answering very complex questions and inducing the
	function of a component when it was only implicitly stated. Understanding
	was further captured by a mental model analysis of the self-explanation
	protocols. High explainers all achieved the correct mental model
	of the circulatory system, whereas many of the unprompted students
	as well as the low explainers did not. Three processing characteristics
	of self-explaining are considered as reasons for the gains in deeper
	understanding. © 1994.},
  doi = {10.1016/0364-0213(94)90016-7},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Chi_1994_Eliciting self-explanations improves understanding.pdf:pdf},
  issn = {03640213},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-43949150689&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Ciresan2012,
  author = {Ciresan, D. and Meier, U. and Schmidhuber, J.},
  title = {{Multi-column deep neural networks for image classification}},
  booktitle = {2012 IEEE Conf. Comput. Vis. Pattern Recognit.},
  year = {2012},
  pages = {3642--3649},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {Traditional methods of computer vision and machine learning cannot
	match human performance on tasks such as the recognition of handwritten
	digits or traffic signs. Our biologically plausible, wide and deep
	artificial neural network architectures can. Small (often minimal)
	receptive fields of convolutional winner-take-all neurons yield large
	network depth, resulting in roughly as many sparsely connected neural
	layers as found in mammals between retina and visual cortex. Only
	winner neurons are trained. Several deep neural columns become experts
	on inputs preprocessed in different ways; their predictions are averaged.
	Graphics cards allow for fast training. On the very competitive MNIST
	handwriting benchmark, our method is the first to achieve near-human
	performance. On a traffic sign recognition benchmark it outperforms
	humans by a factor of two. We also improve the state-of-the-art on
	a plethora of common image classification benchmarks. © 2012 IEEE.},
  doi = {10.1109/CVPR.2012.6248110},
  isbn = {978-1-4673-1228-8},
  issn = {10636919},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866714584&partnerID=tZOtx3y1}
}

@ARTICLE{Ciresan2012a,
  author = {Cire�?an, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber,
	J\"{u}rgen},
  title = {{Multi-column deep neural network for traffic sign classification.}},
  journal = {Neural Netw.},
  year = {2012},
  volume = {32},
  pages = {333--8},
  month = {\#aug\#},
  abstract = {We describe the approach that won the final phase of the German traffic
	sign recognition benchmark. Our method is the only one that achieved
	a better-than-human recognition rate of 99.46%. We use a fast, fully
	parameterizable GPU implementation of a Deep Neural Network (DNN)
	that does not require careful design of pre-wired feature extractors,
	which are rather learned in a supervised way. Combining various DNNs
	trained on differently preprocessed data into a Multi-Column DNN
	(MCDNN) further boosts recognition performance, making the system
	insensitive also to variations in contrast and illumination.},
  doi = {10.1016/j.neunet.2012.02.023},
  issn = {1879-2782},
  keywords = {Algorithms,Automatic Data Processing,Automobile Driving,Automobile
	Driving: psychology,Computer Graphics,Motor Vehicles,Neural Networks
	(Computer),Pattern Recognition, Automated,Vision, Ocular,Vision,
	Ocular: physiology},
  pmid = {22386783},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861776914&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Collobert2008,
  author = {Collobert, Ronan and Weston, Jason},
  title = {{A unified architecture for natural language processing: Deep neural
	networks with multitask learning}},
  booktitle = {Proc. 25th Int. Conf. Mach. Learn.},
  year = {2008},
  pages = {160--167},
  abstract = {We describe a single convolutional neural network architecture that,
	given a sentence, outputs a host of language processing predictions:
	part-of-speech tags, chunks, named entity tags, semantic roles, sernantically
	similar words and the likelihood that the sentence makes sense (grammatically
	and semantically) using a language model. The entire network is trained
	jointly on all these tasks using weight-sharing, an instance of multitask
	learning. All the tasks use labeled data except the language model
	which is learnt from unlabeled text and represents a novel form of
	semi-supervised learning for the shared tasks. We show how both multitask
	learning and semi-supervised learning improve the generalization
	of the shared tasks, resulting in state-of-the-art performance. Copyright
	2008 by the author(s)/owner(s).},
  isbn = {9781605582054},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449095373&partnerID=tZOtx3y1}
}

@ARTICLE{Cortes1995,
  author = {Cortes, C and Vapnik, V},
  title = {{Support-vector networks}},
  journal = {Mach. Learn.},
  year = {1995},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Cortes, Vapnik_1995_Support-vector networks.pdf:pdf},
  url = {http://link.springer.com/article/10.1007/bf00994018}
}

@ARTICLE{Dahl2012,
  author = {Dahl, G. E. and Acero, A.},
  title = {{Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary
	Speech Recognition}},
  journal = {IEEE Trans. Audio. Speech. Lang. Processing},
  year = {2012},
  volume = {20},
  pages = {30--42},
  number = {1},
  month = {\#jan\#},
  abstract = {We propose a novel context-dependent (CD) model for large-vocabulary
	speech recognition (LVSR) that leverages recent advances in using
	deep belief networks for phone recognition. We describe a pre-trained
	deep neural network hidden Markov model (DNN-HMM) hybrid architecture
	that trains the DNN to produce a distribution over senones (tied
	triphone states) as its output. The deep belief network pre-training
	algorithm is a robust and often helpful way to initialize deep neural
	networks generatively that can aid in optimization and reduce generalization
	error. We illustrate the key components of our model, describe the
	procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects
	of various modeling choices on performance. Experiments on a challenging
	business search dataset demonstrate that CD-DNN-HMMs can significantly
	outperform the conventional context-dependent Gaussian mixture model
	(GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8%
	and 9.2% (or relative error reduction of 16.0% and 23.2%) over the
	CD-GMM-HMMs trained using the minimum phone error rate (MPE) and
	maximum-likelihood (ML) criteria, respectively. © 2011 IEEE.},
  doi = {10.1109/TASL.2011.2134090},
  issn = {1558-7916},
  keywords = {Artificial neural network-hidden Markov model (ANN,context-dependent
	phone,deep belief network,deep neural network hidden Markov model
	(DNN-HMM),large-vocabulary speech recognition (LVSR),speech recognition},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84055222005&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Dahl2013,
  author = {Dahl, George E. and Sainath, Tara N. and Hinton, Geoffrey E.},
  title = {{Improving deep neural networks for LVCSR using rectified linear
	units and dropout}},
  booktitle = {2013 IEEE Int. Conf. Acoust. Speech Signal Process.},
  year = {2013},
  pages = {8609--8613},
  month = {\#may\#},
  publisher = {IEEE},
  abstract = {Recently, pre-trained deep neural networks (DNNs) have outperformed
	traditional acoustic models based on Gaussian mixture models (GMMs)
	on a variety of large vocabulary speech recognition benchmarks. Deep
	neural nets have also achieved excellent results on various computer
	vision tasks using a random 'dropout' procedure that drastically
	improves generalization error by randomly omitting a fraction of
	the hidden units in all layers. Since dropout helps avoid over-fitting,
	it has also been successful on a small-scale phone recognition task
	using larger neural nets. However, training deep neural net acoustic
	models for large vocabulary speech recognition takes a very long
	time and dropout is likely to only increase training time. Neural
	networks with rectified linear unit (ReLU) non-linearities have been
	highly successful for computer vision tasks and proved faster to
	train than standard sigmoid units, sometimes also improving discriminative
	performance. In this work, we show on a 50-hour English Broadcast
	News task that modified deep neural networks using ReLUs trained
	with dropout during frame level training provide an 4.2% relative
	improvement over a DNN trained with sigmoid units, and a 14.4% relative
	improvement over a strong GMM/HMM system. We were able to obtain
	our results with minimal human hyper-parameter tuning using publicly
	available Bayesian optimization code. © 2013 IEEE.},
  doi = {10.1109/ICASSP.2013.6639346},
  isbn = {978-1-4799-0356-6},
  issn = {15206149},
  keywords = {Bayesian optimization,LVCSR,acoustic modeling,broadcast news,deep
	learning,dropout,neural networks,rectified linear units},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890527827&partnerID=tZOtx3y1}
}

@ARTICLE{Deng2014,
  author = {Deng, L},
  title = {{A tutorial survey of architectures, algorithms, and applications
	for deep learning}},
  journal = {APSIPA Trans. Signal Inf. \ldots},
  year = {2014},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng_2014_A tutorial survey of architectures, algorithms, and applications for deep learning.pdf:pdf},
  url = {http://journals.cambridge.org/abstract_S2048770313000097}
}

@ARTICLE{Deng2013,
  author = {Deng, Li and Yu, Dong},
  title = {{Deep Learning: Methods and Applications}},
  journal = {Found. Trends Signal Process.},
  year = {2013},
  volume = {7},
  pages = {197----387},
  abstract = {This book is aimed to provide an overview of general deep learning
	methodology and its applications to a variety of signal and information
	processing tasks. The application areas are chosen with the following
	three criteria: 1) expertise or knowledge of the authors; 2) the
	application areas that have already been transformed by the successful
	use of deep learning technology, such as speech recognition and computer
	vision; and 3) the application areas that have the potential to be
	impacted significantly by deep learning and that have gained concentrated
	research efforts, including natural language and text processing,
	information retrieval, and multimodal information processing empowered
	by multi-task deep learning. In Chapter 1, we provide the background
	of deep learning, as intrinsically connected to the use of multiple
	layers of nonlinear transformations to derive features from the sensory
	signals such as speech and visual images. In the most recent literature,
	deep learning is embodied also as representation learning, which
	involves a hierarchy of features or concepts where higher-level representations
	of them are defined from lower-level ones and where the same lower-level
	representations help to define higher-level ones. In Chapter 2, a
	brief historical account of deep learning is presented. In particular,
	selected chronological development of speech recognition is used
	to illustrate the recent impact of deep learning that has become
	a dominant technology in speech recognition industry within only
	a few years since the start of a collaboration between academic and
	industrial researchers in applying deep learning to speech recognition.
	In Chapter 3, a three-way classification scheme for a large body
	of work in deep learning is developed. We classify a growing number
	of deep learning techniques into unsupervised, supervised, and hybrid
	categories, and present qualitative descriptions and a literature
	survey for each category. From Chapter 4 to Chapter 6, we discuss
	in detail three popular deep networks and related learning methods,
	one in each category. Chapter 4 is devoted to deep autoencoders as
	a prominent example of the unsupervised deep learning techniques.
	Chapter 5 gives a major example in the hybrid deep network category,
	which is the discriminative feed-forward neural network for supervised
	learning with many layers initialized using layer-by-layer generative,
	unsupervised pre-training. In Chapter 6, deep stacking networks and
	several of the variants are discussed in detail, which exemplify
	the discriminative or supervised deep learning techniques in the
	three-way categorization scheme. In Chapters 7-11, we select a set
	of typical and successful applications of deep learning in diverse
	areas of signal and information processing and of applied artificial
	intelligence. In Chapter 7, we review the applications of deep learning
	to speech and audio processing, with emphasis on speech recognition
	organized according to several prominent themes. In Chapters 8, we
	present recent results of applying deep learning to language modeling
	and natural language processing. Chapter 9 is devoted to selected
	applications of deep learning to information retrieval including
	Web search. In Chapter 10, we cover selected applications of deep
	learning to image object recognition in computer vision. Selected
	applications of deep learning to multi-modal processing and multi-task
	learning are reviewed in Chapter 11. Finally, an epilogue is given
	in Chapter 12 to summarize what we presented in earlier chapters
	and to discuss future challenges and directions.},
  doi = {10.1136/bmj.319.7209.0a},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng, Yu_2013_Deep Learning Methods and Applications.pdf:pdf},
  isbn = {9781405161251},
  issn = {09598138},
  pmid = {10463930}
}

@MISC{Deselaers,
  author = {Deselaers, T. and Hasan, S. and Bender, O. and Ney, H.},
  title = {{A deep learning approach to machine transliteration}},
  booktitle = {Proc. EACL 2009Workshop Stat. Mach. Transl.},
  pages = {233--241},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70450166894&partnerID=tZOtx3y1}
}

@ARTICLE{Egmont-Petersen2002,
  author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
  title = {{Image processing with neural networks—a review}},
  journal = {Pattern Recognit.},
  year = {2002},
  volume = {35},
  pages = {2279--2301},
  number = {10},
  month = {\#oct\#},
  abstract = {We review more than 200 applications of neural networks in image processing
	and discuss the present and possible future role of neural networks,
	especially feed-forward neural networks, Kohonen feature maps and
	Hopfield neural networks. The various applications are categorised
	into a novel two-dimensional taxonomy for image processing algorithms.
	One dimension specifies the type of task performed by the algorithm:
	preprocessing, data reduction/feature extraction, segmentation, object
	recognition, image understanding and optimisation. The other dimension
	captures the abstraction level of the input data processed by the
	algorithm: pixel-level, local feature-level, structure-level, object-level,
	object-set-level and scene characterisation. Each of the six types
	of tasks poses specific constraints to a neural-based approach. These
	specific conditions are discussed in detail. A synthesis is made
	of unresolved problems related to the application of pattern recognition
	techniques in image processing and specifically to the application
	of neural networks. Finally, we present an outlook into the future
	application of neural networks and relate them to novel developments.},
  doi = {10.1016/S0031-3203(01)00178-9},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels_2002_Image processing with neural networks—a review.pdf:pdf},
  issn = {00313203},
  keywords = {Digital image processing,Feature extraction,Image compression,Image
	understanding,Invariant pattern recognition,Neural networks,Object
	recognition,Optimization,Preprocessing,Segmentation},
  url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789}
}

@ARTICLE{Erhan2010,
  author = {Erhan, Dumitru and Courville, Aaron and Vincent, Pascal and Bengio,
	Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine Antoine
	and Vincent, Pascal and Bengio, Samy},
  title = {{Why Does Unsupervised Pre-training Help Deep Learning ?}},
  journal = {J. Mach. Learn. Res.},
  year = {2010},
  volume = {11},
  pages = {625--660},
  month = {\#mar\#},
  abstract = {Much recent research has been devoted to learning algorithms for deep
	architectures such as Deep Belief Networks and stacks of auto-encoder
	variants, with impressive results obtained in several areas, mostly
	on vision and language data sets. The best results obtained on supervised
	learning tasks involve an unsupervised learning component, usually
	in an unsupervised pre-training phase. Even though these new algorithms
	have enabled training deep models, many questions remain as to the
	nature of this difficult learning problem. The main question investigated
	here is the following: how does unsupervised pre-training work? Answering
	this questions is important if learning in deep architectures is
	to be further improved. We propose several explanatory hypotheses
	and test them through extensive simulations. We empirically show
	the influence of pre-training with respect to architecture depth,
	model capacity, and number of training examples. The experiments
	confirm and clarify the advantage of unsupervised pre-training. The
	results suggest that unsupervised pre-training guides the learning
	towards basins of attraction of minima that support better generalization
	from the training data set; the evidence from these results supports
	a regularization explanation for the effect of pre-training.},
  archiveprefix = {arXiv},
  arxivid = {arXiv:1206.5538v1},
  eprint = {arXiv:1206.5538v1},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Erhan et al._2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:pdf},
  issn = {15324435},
  keywords = {AutoEnc,Deep architectures,Deep belief networks,GenDL,Non-convex optimization,Stacked
	denoising auto-encoders,Unsupervised,Unsupervised pre-training,deep
	architectures,deep belief networks,non-convex optimization,stacked
	denoising auto-encoders,unsupervised pre-training},
  mendeley-tags = {AutoEnc,GenDL,Unsupervised},
  publisher = {JMLR.org},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77949522811&partnerID=tZOtx3y1 http://dl.acm.org/citation.cfm?id=1756006.1756025 http://portal.acm.org/citation.cfm?id=1756025}
}

@ARTICLE{Erman2007,
  author = {Erman, Jeffrey and Mahanti, Anirban and Arlitt, Martin and Cohen,
	Ira and Williamson, Carey},
  title = {{Offline/realtime traffic classification using semi-supervised learning}},
  journal = {Perform. Eval.},
  year = {2007},
  volume = {64},
  pages = {1194--1213},
  number = {9-12},
  month = {\#oct\#},
  abstract = {Identifying and categorizing network traffic by application type is
	challenging because of the continued evolution of applications, especially
	of those with a desire to be undetectable. The diminished effectiveness
	of port-based identification and the overheads of deep packet inspection
	approaches motivate us to classify traffic by exploiting distinctive
	flow characteristics of applications when they communicate on a network.
	In this paper, we explore this latter approach and propose a semi-supervised
	classification method that can accommodate both known and unknown
	applications. To the best of our knowledge, this is the first work
	to use semi-supervised learning techniques for the traffic classification
	problem. Our approach allows classifiers to be designed from training
	data that consists of only a few labeled and many unlabeled flows.
	We consider pragmatic classification issues such as longevity of
	classifiers and the need for retraining of classifiers. Our performance
	evaluation using empirical Internet traffic traces that span a 6-month
	period shows that: (1) high flow and byte classification accuracy
	(i.e., greater than 90%) can be achieved using training data that
	consists of a small number of labeled and a large number of unlabeled
	flows; (2) presence of "mice" and "elephant" flows in the Internet
	complicates the design of classifiers, especially of those with high
	byte accuracy, and necessitates the use of weighted sampling techniques
	to obtain training flows; and (3) retraining of classifiers is necessary
	only when there are non-transient changes in the network usage characteristics.
	As a proof of concept, we implement prototype offline and realtime
	classification systems to demonstrate the feasibility of our approach.
	© 2007.},
  doi = {10.1016/j.peva.2007.06.014},
  issn = {01665316},
  keywords = {Internet traffic classification,Machine learning,Realtime classification,Semi-supervised
	learning},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548118248&partnerID=tZOtx3y1}
}

@ARTICLE{Farabet2013,
  author = {Farabet, Cl\'{e}ment and Couprie, Camille and Najman, Laurent and
	Lecun, Yann},
  title = {{Learning hierarchical features for scene labeling.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2013},
  volume = {35},
  pages = {1915--29},
  number = {8},
  month = {\#aug\#},
  abstract = {Scene labeling consists of labeling each pixel in an image with the
	category of the object it belongs to. We propose a method that uses
	a multiscale convolutional network trained from raw pixels to extract
	dense feature vectors that encode regions of multiple sizes centered
	on each pixel. The method alleviates the need for engineered features,
	and produces a powerful representation that captures texture, shape,
	and contextual information. We report results using multiple postprocessing
	methods to produce the final labeling. Among those, we propose a
	technique to automatically retrieve, from a pool of segmentation
	components, an optimal set of components that best explain the scene;
	these components are arbitrary, for example, they can be taken from
	a segmentation tree or from any family of oversegmentations. The
	system yields record accuracies on the SIFT Flow dataset (33 classes)
	and the Barcelona dataset (170 classes) and near-record accuracy
	on Stanford background dataset (eight classes), while being an order
	of magnitude faster than competing approaches, producing a $(320\times
	240)$ image labeling in less than a second, including feature extraction.},
  doi = {10.1109/TPAMI.2012.231},
  issn = {1939-3539},
  keywords = {Convolutional networks,deep learning,image classification,image segmentation,scene
	parsing},
  pmid = {23787344},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876258641&partnerID=tZOtx3y1}
}

@ARTICLE{Ferragina2005,
  author = {Ferragina, Paolo and Giancarlo, Raffaele and Manzini, Giovanni and
	Sciortino, Marinella},
  title = {{Boosting textual compression in optimal linear time}},
  journal = {J. ACM},
  year = {2005},
  volume = {52},
  pages = {688--713},
  number = {4},
  month = {\#jul\#},
  abstract = {We provide a general boosting technique for Textual Data Compression.
	Qualitatively, it takes a good compression algorithm and turns it
	into an algorithm with a better compression performance guarantee.
	It displays the following remarkable properties: (a) it can turn
	any memoryless compressor into a compression algorithm that uses
	the "best possible" contexts; (b) it is very simple and optimal in
	terms of time; and (c) it admits a decompression algorithm again
	optimal in time. To the best of our knowledge, this is the first
	boosting technique displaying these properties. Technically, our
	boosting technique builds upon three main ingredients: the Burrows-Wheeler
	Transform, the Suffix Tree data structure, and a greedy algorithm
	to process them. Specifically, we show that there exists a proper
	partition of the Burrows-Wheeler Transform of a string 5 that shows
	a deep combinatorial relation with the kth order entropy of s. That
	partition can be identified via a greedy processing of the suffix
	tree of s with the aim of minimizing a proper objective function
	over its nodes. The final compressed string is then obtained by compressing
	individually each substring of the partition by means of the base
	compressor we wish to boost. Our boosting technique is inherently
	combinatorial because it does not need to assume any prior probabilistic
	model about the source emitting s, and it does not deploy any training,
	parameter estimation and learning. Various corollaries are derived
	from this main achievement. Among the others, we show analytically
	that using our booster, we get better compression algorithms than
	some of the best existing ones, that is, LZ77, LZ78, PPMC and the
	ones derived from the Burrows-Wheeler Transform. Further, we settle
	analytically some long-standing open problems about the algorithmic
	structure and the performance of BWT-based compressors. Namely, we
	provide the first family of BWT algorithms that do not use Move-To-Front
	or Symbol Ranking as a part of the compression process.© 2005 ACM.},
  doi = {10.1145/1082036.1082043},
  issn = {00045411},
  keywords = {Arithmetic coding,Burrows-Wheeler transform,Empirical entropy,Huffman
	coding,Lempel-Ziv compressors,Suffix tree,Text compression},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-30544455566&partnerID=tZOtx3y1}
}

@ARTICLE{Fukushima2003,
  author = {Fukushima, Kunihiko},
  title = {{Neocognitron for handwritten digit recognition}},
  journal = {Neurocomputing},
  year = {2003},
  volume = {51},
  pages = {161--180},
  month = {\#apr\#},
  abstract = {The author previously proposed a neural network model neocognitron
	for robust visual pattern recognition. This paper proposes an improved
	version of the neocognitron and demonstrates its ability using a
	large database of handwritten digits (ETL1). To improve the recognition
	rate of the neocognitron, several modifications have been applied:
	such as, the inhibitory surround in the connections from S-cells
	to C-cells, contrast-extracting layer between input and edge-extracting
	layers, self-organization of line-extracting cells, supervised competitive
	learning at the highest stage, staggered arrangement of S- and C-cells,
	and so on. These modifications allowed the removal of accessory circuits
	that were appended to the previous versions, resulting in an improvement
	of recognition rate as well as simplification of the network architecture.
	The recognition rate varies depending on the number of training patterns.
	When we used 3000 digits (300 patterns for each digit) for the learning,
	for example, the recognition rate was 98.6% for a blind test set
	(3000 digits), and 100% for the training set.},
  doi = {10.1016/S0925-2312(02)00614-8},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_2003_Neocognitron for handwritten digit recognition.pdf:pdf},
  issn = {09252312},
  keywords = {Handwritten digit,Multi-layered network,Neocognitron,Neural network
	model,Visual pattern recognition},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231202006148}
}

@ARTICLE{Fukushima1980,
  author = {Fukushima, Kunihiko},
  title = {{Neocognitron: A self-organizing neural network model for a mechanism
	of pattern recognition unaffected by shift in position}},
  journal = {Biol. Cybern.},
  year = {1980},
  volume = {36},
  pages = {193--202},
  number = {4},
  month = {\#apr\#},
  doi = {10.1007/BF00344251},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_1980_Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in positio.pdf:pdf},
  issn = {0340-1200},
  url = {http://link.springer.com/10.1007/BF00344251}
}

@ARTICLE{G.E.Hinton,
  author = {{G. E. Hinton, A. Krizhevsky}, S. D. Wang},
  title = {{Transforming Auto-encoders}},
  journal = {Artif. Neural Networks Mach. Learn. 2011.},
  year = {2011},
  pages = {44--51.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/G. E. Hinton, A. Krizhevsky_2011_Transforming Auto-encoders.pdf:pdf},
  keywords = {Vision},
  mendeley-tags = {Vision},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.220.5099}
}

@ARTICLE{Garcia2002,
  author = {Garcia, C and Delakis, M},
  title = {{A neural architecture for fast and robust face detection}},
  journal = {Pattern Recognition, 2002. Proceedings. 16th Int. Conf.},
  year = {2002},
  volume = {2},
  pages = {44 -- 47 vol.2},
  number = {11},
  abstract = { In this paper, we present a connectionist approach for detecting
	and precisely localizing semi-frontal human faces in complex images,
	making no assumption about the content or the lighting conditions
	of the scene, or about the size or the appearance of the faces. We
	propose a convolutional neural network architecture designed to recognize
	strongly variable face patterns directly from pixel images with no
	preprocessing, by automatically synthesizing its own set of feature
	extractors from a large training set of faces. We present in details
	the optimized design of our architecture, our learning strategy and
	the resulting process of face detection. We also provide experimental
	results to demonstrate the robustness of our approach and its capability
	to precisely detect extremely variable faces in uncontrolled environments.},
  doi = {10.1109/ICPR.2002.1048232},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Garcia, Delakis_2002_A neural architecture for fast and robust face detection.pdf:pdf},
  issn = {1051-4651},
  keywords = {automatic synthesis; complex images; connectionist}
}

@INPROCEEDINGS{Glorot2011,
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  title = {{Domain adaptation for large-scale sentiment classification: A deep
	learning approach}},
  booktitle = {Proc. 28th Int. Conf. Mach. Learn. ICML 2011},
  year = {2011},
  pages = {513--520},
  abstract = {The exponential increase in the availability of online reviews and
	recommendations makes sentiment classification an interesting topic
	in academic and industrial research. Reviews can span so many different
	domains that it is difficult to gather annotated training data for
	all of them. Hence, this paper studies the problem of domain adaptation
	for sentiment classifiers, hereby a system is trained on labeled
	reviews from one source domain but is meant to be deployed on another.
	We propose a deep learning approach which learns to extract a meaningful
	representation for each review in an unsupervised fashion. Sentiment
	classifiers trained with this high-level feature representation clearly
	outperform state-of-the-art methods on a benchmark composed of reviews
	of 4 types of Amazon products. Furthermore, this method scales well
	and allowed us to successfully perform domain adaptation on a larger
	industrial-strength dataset of 22 domains. Copyright 2011 by the
	author(s)/owner(s).},
  isbn = {9781450306195},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053443013&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Goodfellow2009,
  author = {Goodfellow, Ian J. and Le, Quoc V. and Saxe, Andrew M. and Lee, Honglak
	and Ng, Andrew Y.},
  title = {{Measuring invariances in deep networks}},
  booktitle = {Adv. Neural Inf. Process. Syst. 22 - Proc. 2009 Conf.},
  year = {2009},
  pages = {646--654},
  abstract = {For many pattern recognition tasks, the ideal input feature would
	be invariant to multiple confounding properties (such as illumination
	and viewing angle, in computer vision applications). Recently, deep
	architectures trained in an unsupervised manner have been proposed
	as an automatic method for extracting useful features. However, it
	is difficult to evaluate the learned features by any means other
	than using them in a classifier. In this paper, we propose a number
	of empirical tests that directly measure the degree to which these
	learned features are invariant to different input transformations.
	We find that stacked autoencoders learn modestly increasingly invariant
	features with depth when trained on natural images. We find that
	convolutional deep belief networks learn substantially more invariant
	features in each layer. These results further justify the use of
	"deep" vs. "shallower" representations, but suggest that mechanisms
	beyond merely stacking one autoencoder on top of another may be important
	for achieving invariance. Our evaluation metrics can also be used
	to evaluate future work in deep learning, and thus help the development
	of future algorithms.},
  isbn = {9781615679119},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860644702&partnerID=tZOtx3y1}
}

@BOOK{Hardle2004,
  title = {{Nonparametric and Semiparametric Models}},
  publisher = {Springer Berlin Heidelberg},
  year = {2004},
  author = {H\"{a}rdle, Wolfgang and Werwatz, Axel and M\"{u}ller, Marlene and
	Sperlich, Stefan},
  series = {Springer Series in Statistics},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-17146-8},
  isbn = {978-3-642-62076-8},
  url = {http://link.springer.com/10.1007/978-3-642-17146-8}
}

@INPROCEEDINGS{Hamel2010,
  author = {Hamel, Philippe and Eck, Douglas},
  title = {{Learning features from music audio with deep belief networks}},
  booktitle = {Proc. 11th Int. Soc. Music Inf. Retr. Conf. ISMIR 2010},
  year = {2010},
  pages = {339--344},
  abstract = {Feature extraction is a crucial part of many MIR tasks. In this work,
	we present a system that can automatically extract relevant features
	from audio for a given task. The feature extraction system consists
	of a Deep Belief Network (DBN) on Discrete Fourier Transforms (DFTs)
	of the audio. We then use the activations of the trained network
	as inputs for a non-linear Support Vector Machine (SVM) classifier.
	In particular, we learned the features to solve the task of genre
	recognition. The learned features perform significantly better than
	MFCCs. Moreover, we obtain a classification accuracy of 84.3% on
	the Tzanetakis dataset, which compares favorably against state-of-the-art
	genre classifiers using frame-based features. We also applied these
	same features to the task of auto-tagging. The autotaggers trained
	with our features performed better than those that were trained with
	timbral and temporal features. © 2010 International Society for Music
	Information Retrieval.},
  isbn = {9789039353813},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84873584268&partnerID=tZOtx3y1}
}

@ARTICLE{Hinton2007,
  author = {Hinton, Geoffrey E},
  title = {{Learning multiple layers of representation.}},
  journal = {Trends Cogn. Sci.},
  year = {2007},
  volume = {11},
  pages = {428--34},
  number = {10},
  month = {\#oct\#},
  abstract = {To achieve its impressive performance in tasks such as speech perception
	or object recognition, the brain extracts multiple levels of representation
	from the sensory input. Backpropagation was the first computationally
	efficient model of how neural networks could learn multiple layers
	of representation, but it required labeled training data and it did
	not work well in deep networks. The limitations of backpropagation
	learning can now be overcome by using multilayer neural networks
	that contain top-down connections and training them to generate sensory
	data rather than to classify it. Learning multilayer generative models
	might seem difficult, but a recent discovery makes it easy to learn
	nonlinear distributed representations one layer at a time.},
  doi = {10.1016/j.tics.2007.09.004},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton_2007_Learning multiple layers of representation.pdf:pdf},
  issn = {1364-6613},
  keywords = {Brain,Brain: physiology,Humans,Learning,Learning: physiology,Models,Nerve
	Net,Nerve Net: physiology,Psychological},
  pmid = {17921042},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661307002173}
}

@ARTICLE{Hinton2006a,
  author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  title = {{A fast learning algorithm for deep belief nets.}},
  journal = {Neural Comput.},
  year = {2006},
  volume = {18},
  pages = {1527--54},
  number = {7},
  month = {\#jul\#},
  abstract = {We show how to use "complementary priors" to eliminate the explaining-away
	effects that make inference difficult in densely connected belief
	nets that have many hidden layers. Using complementary priors, we
	derive a fast, greedy algorithm that can learn deep, directed belief
	networks one layer at a time, provided the top two layers form an
	undirected associative memory. The fast, greedy algorithm is used
	to initialize a slower learning procedure that fine-tunes the weights
	using a contrastive version of the wake-sleep algorithm. After fine-tuning,
	a network with three hidden layers forms a very good generative model
	of the joint distribution of handwritten digit images and their labels.
	This generative model gives better digit classification than the
	best discriminative learning algorithms. The low-dimensional manifolds
	on which the digits lie are modeled by long ravines in the free-energy
	landscape of the top-level associative memory, and it is easy to
	explore these ravines by using the directed connections to display
	what the associative memory has in mind.},
  doi = {10.1162/neco.2006.18.7.1527},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Osindero, Teh_2006_A fast learning algorithm for deep belief nets.pdf:pdf},
  issn = {0899-7667},
  keywords = {Algorithms,Animals,DBN,Humans,Learning,Learning: physiology,Neural
	Networks (Computer),Neurons,Neurons: physiology},
  mendeley-tags = {DBN},
  pmid = {16764513},
  shorttitle = {Neural Computation},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513 http://www.scopus.com/inward/record.url?eid=2-s2.0-33745805403&partnerID=tZOtx3y1}
}

@ARTICLE{Hinton2006,
  author = {Hinton, G E and Salakhutdinov, R R},
  title = {{Reducing the dimensionality of data with neural networks.}},
  journal = {Science},
  year = {2006},
  volume = {313},
  pages = {504--507},
  number = {5786},
  month = {\#jul\#},
  abstract = {High-dimensional data can be converted to low-dimensional codes by
	training a multilayer neural network with a small central layer to
	reconstruct high-dimensional input vectors. Gradient descent can
	be used for fine-tuning the weights in such "autoencoder" networks,
	but this works well only if the initial weights are close to a good
	solution. We describe an effective way of initializing the weights
	that allows deep autoencoder networks to learn low-dimensional codes
	that work much better than principal components analysis as a tool
	to reduce the dimensionality of data.},
  doi = {10.1126/science.1127647},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Salakhutdinov_2006_Reducing the dimensionality of data with neural networks.pdf:pdf},
  isbn = {3135786504},
  issn = {0036-8075},
  pmid = {16873662},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746600649&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Huang2012,
  author = {Huang, G. B. and Learned-Miller, E.},
  title = {{Learning hierarchical representations for face verification with
	convolutional deep belief networks}},
  booktitle = {2012 IEEE Conf. Comput. Vis. Pattern Recognit.},
  year = {2012},
  pages = {2518--2525},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {Most modern face recognition systems rely on a feature representation
	given by a hand-crafted image descriptor, such as Local Binary Patterns
	(LBP), and achieve improved performance by combining several such
	representations. In this paper, we propose deep learning as a natural
	source for obtaining additional, complementary representations. To
	learn features in high-resolution images, we make use of convolutional
	deep belief networks. Moreover, to take advantage of global structure
	in an object class, we develop local convolutional restricted Boltzmann
	machines, a novel convolutional learning model that exploits the
	global structure by not assuming stationarity of features across
	the image, while maintaining scalability and robustness to small
	misalignments. We also present a novel application of deep learning
	to descriptors other than pixel intensity values, such as LBP. In
	addition, we compare performance of networks trained using unsupervised
	learning against networks with random filters, and empirically show
	that learning weights not only is necessary for obtaining good multilayer
	representations, but also provides robustness to the choice of the
	network architecture parameters. Finally, we show that a recognition
	system using only representations obtained from deep learning can
	achieve comparable accuracy with a system using a combination of
	hand-crafted image descriptors. Moreover, by combining these representations,
	we achieve state-of-the-art results on a real-world face verification
	database. © 2012 IEEE.},
  doi = {10.1109/CVPR.2012.6247968},
  isbn = {978-1-4673-1228-8},
  issn = {10636919},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866691616&partnerID=tZOtx3y1}
}

@ARTICLE{Ji2013,
  author = {Ji, Shuiwang and Yang, Ming and Yu, Kai},
  title = {{3D convolutional neural networks for human action recognition.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2013},
  volume = {35},
  pages = {221--31},
  number = {1},
  month = {\#jan\#},
  abstract = {We consider the automated recognition of human actions in surveillance
	videos. Most current methods build classifiers based on complex handcrafted
	features computed from the raw inputs. Convolutional neural networks
	(CNNs) are a type of deep model that can act directly on the raw
	inputs. However, such models are currently limited to handling 2D
	inputs. In this paper, we develop a novel 3D CNN model for action
	recognition. This model extracts features from both the spatial and
	the temporal dimensions by performing 3D convolutions, thereby capturing
	the motion information encoded in multiple adjacent frames. The developed
	model generates multiple channels of information from the input frames,
	and the final feature representation combines information from all
	channels. To further boost the performance, we propose regularizing
	the outputs with high-level features and combining the predictions
	of a variety of different models. We apply the developed models to
	recognize human actions in the real-world environment of airport
	surveillance videos, and they achieve superior performance in comparison
	to baseline methods.},
  doi = {10.1109/TPAMI.2012.59},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ji, Yang, Yu_2013_3D convolutional neural networks for human action recognition.pdf:pdf},
  issn = {1939-3539},
  keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted:
	methods,Decision Support Techniques,Image Interpretation,Imaging,Movement,Movement:
	physiology,Neural Networks (Computer),Pattern Recognition,Subtraction
	Technique,Three-Dimensional,Three-Dimensional: methods},
  pmid = {22392705},
  shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/22392705}
}

@MISC{Kingsbury,
  author = {Kingsbury, B. and Sainath, T.N. and Soltau, H.},
  title = {{Scalable minimum bayes risk training of neural network acoustic
	models using distributed hessian-free optimization}},
  booktitle = {Proc. Interspeech},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878379171&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Krizhevsky2012,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2012},
  pages = {1097--1105},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
  keywords = {CNN},
  mendeley-tags = {CNN},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional}
}

@INPROCEEDINGS{Larochelle2008,
  author = {Larochelle, Hugo and Bengio, Yoshua},
  title = {{Classification using discriminative restricted boltzmann machines}},
  booktitle = {Proc. 25th Int. Conf. Mach. Learn.},
  year = {2008},
  pages = {536--543},
  abstract = {Recently, many applications for Restricted Boltzmann Machines (RBMs)
	have been developed for a large variety of learning problems. However,
	RBMs are usually used as feature extractors for another learning
	algorithm or to provide a good initialization for deep feed-forward
	neural network classifiers, and are not considered as a stand-alone
	solution to classification problems. In this paper, we argue that
	RBMs provide a self-contained framework for deriving competitive
	non-linear classifiers. We present an evaluation of different learning
	algorithms for RBMs which aim at introducing a discriminative component
	to RBM training and improve their performance as classifiers. This
	approach is simple in that RBMs are used directly to build a classifier,
	rather than as a stepping stone. Finally, we demonstrate how discriminative
	RBMs can also be successfully employed in a semi-supervised setting.
	Copyright 2008 by the author(s)/owner(s).},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Larochelle, Bengio_2008_Classification using discriminative restricted boltzmann machines.pdf:pdf},
  isbn = {9781605582054},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449110012&partnerID=tZOtx3y1}
}

@ARTICLE{Larochelle2009,
  author = {Larochelle, Hugo and Bengio, Yoshua and Louradour, J\'{e}r\^{o}me
	and Lamblin, Pascal},
  title = {{Exploring strategies for training deep neural networks}},
  journal = {J. Mach. Learn. Res.},
  year = {2009},
  volume = {10},
  pages = {1--40},
  abstract = {Deep multi-layer neural networks have many levels of non-linearities
	allowing them to compactly represent highly non-linear and highly-varying
	functions. However, until recently it was not clear how to train
	such deep networks, since gradient-based optimization starting from
	random initialization often appears to get stuck in poor solutions.
	Hinton et al. recently proposed a greedy layer-wise unsupervised
	learning procedure relying on the training algorithm of restricted
	Boltzmann machines (RBM) to initialize the parameters of a deep belief
	network (DBN), a generative model with many layers of hidden causal
	variables. This was followed by the proposal of another greedy layer-wise
	procedure, relying on the usage of autoassociator networks. In the
	context of the above optimization problem, we study these algorithms
	empirically to better understand their success. Our experiments confirm
	the hypothesis that the greedy layer-wise unsupervised training strategy
	helps the optimization by initializing weights in a region near a
	good local minimum, but also implicitly acts as a sort of regularization
	that brings better generalization and encourages internal distributed
	representations that are high-level abstractions of the input. We
	also present a series of experiments aimed at evaluating the link
	between the performance of deep neural networks and practical aspects
	of their topology, for example, demonstrating cases where the addition
	of more depth helps. Finally, we empirically explore simple variants
	of these training algorithms, such as the use of different RBM input
	unit distributions, a simple way of combining gradient estimators
	to improve performance, as well as on-line versions of those algorithms.},
  issn = {15324435},
  keywords = {Artificial neural networks,Autoassociators,Deep belief networks,Restricted
	Boltzmann machines,Unsupervised learning},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-59449087310&partnerID=tZOtx3y1}
}

@ARTICLE{Larochelle2012,
  author = {Larochelle, Hugo and Mandel, Michael and Pascanu, Razvan and Bengio,
	Yoshua},
  title = {{Learning algorithms for the classification restricted Boltzmann
	machine}},
  journal = {J. Mach. Learn. Res.},
  year = {2012},
  volume = {13},
  pages = {643--669},
  abstract = {Recent developments have demonstrated the capacity of restricted Boltzmann
	machines (RBM) to be powerful generative models, able to extract
	useful features from input data or construct deep artificial neural
	networks. In such settings, the RBMonly yields a preprocessing or
	an initialization for some other model, instead of acting as a complete
	supervised model in its own right. In this paper, we argue that RBMs
	can provide a self-contained framework for developing competitive
	classifiers. We study the Classification RBM (ClassRBM), a variant
	on the RBM adapted to the classification setting. We study different
	strategies for training the ClassRBM and show that competitive classification
	performances can be reached when appropriately combining discriminative
	and generative training objectives. Since training according to the
	generative objective requires the computation of a generally intractable
	gradient, we also compare different approaches to estimating this
	gradient and address the issue of obtaining such a gradient for problems
	with very high dimensional inputs. Finally, we describe how to adapt
	the ClassRBM to two special cases of classification problems, namely
	semi-supervised and multitask learning. © 2012 Hugo Larochelle, Michael
	Mandel, Razvan Pascanu and Yoshua Bengio.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Larochelle et al._2012_Learning algorithms for the classification restricted Boltzmann machine.pdf:pdf},
  issn = {15324435},
  keywords = {Classification,Discriminative learning,Generative learning,Restricted
	Boltzmannmachine},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84859473821&partnerID=tZOtx3y1}
}

@ARTICLE{Lawrence1997,
  author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
  title = {{Face recognition: a convolutional neural-network approach.}},
  journal = {IEEE Trans. Neural Netw.},
  year = {1997},
  volume = {8},
  pages = {98--113},
  number = {1},
  month = {\#jan\#},
  abstract = {We present a hybrid neural-network for human face recognition which
	compares favourably with other methods. The system combines local
	image sampling, a self-organizing map (SOM) neural network, and a
	convolutional neural network. The SOM provides a quantization of
	the image samples into a topological space where inputs that are
	nearby in the original space are also nearby in the output space,
	thereby providing dimensionality reduction and invariance to minor
	changes in the image sample, and the convolutional neural network
	provides partial invariance to translation, rotation, scale, and
	deformation. The convolutional network extracts successively larger
	features in a hierarchical set of layers. We present results using
	the Karhunen-Loeve transform in place of the SOM, and a multilayer
	perceptron (MLP) in place of the convolutional network for comparison.
	We use a database of 400 images of 40 individuals which contains
	quite a high degree of variability in expression, pose, and facial
	details. We analyze the computational complexity and discuss how
	new classes could be added to the trained recognizer.},
  doi = {10.1109/72.554195},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lawrence et al._1997_Face recognition a convolutional neural-network approach.pdf:pdf},
  issn = {1045-9227},
  keywords = {CNN,Face recognition,Feature extraction,Humans,Image databases,Image
	sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural
	networks,Quantization,Spatial databases,computational complexity,convolution,convolutional
	neural-network,dimensionality reduction,face recognition,feature
	extraction,image matching,invariance,local image sampling,quantisation
	(signal),quantization,self-organising feature maps,self-organizing
	map,template matching,topological space,topology},
  mendeley-tags = {CNN},
  pmid = {18255614},
  shorttitle = {Neural Networks, IEEE Transactions on},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614}
}

@ARTICLE{LeRoux2008,
  author = {{Le Roux}, Nicolas and Bengio, Yoshua},
  title = {{Representational power of restricted boltzmann machines and deep
	belief networks.}},
  journal = {Neural Comput.},
  year = {2008},
  volume = {20},
  pages = {1631--49},
  number = {6},
  month = {\#jun\#},
  abstract = {Deep belief networks (DBN) are generative neural network models with
	many layers of hidden explanatory factors, recently introduced by
	Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised
	learning algorithm. The building block of a DBN is a probabilistic
	model called a restricted Boltzmann machine (RBM), used to represent
	one layer of the model. Restricted Boltzmann machines are interesting
	because inference is easy in them and because they have been successfully
	used as building blocks for training deeper models. We first prove
	that adding hidden units yields strictly improved modeling power,
	while a second theorem shows that RBMs are universal approximators
	of discrete distributions. We then study the question of whether
	DBNs with more layers are strictly more powerful in terms of representational
	power. This suggests a new and less greedy criterion for training
	RBMs within DBNs.},
  doi = {10.1162/neco.2008.04-07-510},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Le Roux, Bengio_2008_Representational power of restricted boltzmann machines and deep belief networks.pdf:pdf},
  issn = {0899-7667},
  keywords = {Algorithms,Animals,Computer Simulation,Computer-Assisted,Humans,Learning,Learning:
	physiology,Models,Neural Networks (Computer),Signal Processing,Statistical},
  pmid = {18254699},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-45749110924&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Le2011a,
  author = {Le, Quoc V. and Ngiam, Jiquan and Coates, Adam and Lahiri, Abhik
	and Prochnow, Bobby and Ng, Andrew Y.},
  title = {{On optimization methods for deep learning}},
  booktitle = {Proc. 28th Int. Conf. Mach. Learn. ICML 2011},
  year = {2011},
  pages = {265--272},
  abstract = {The predominant methodology in training deep learning advocates the
	use of stochastic gradient descent methods (SGDs). Despite its ease
	of implementation, SGDs are difficult to tune and parallelize. These
	problems make it challenging to develop, debug and scale up deep
	learning algorithms with SGDs. In this paper, we show that more sophisticated
	off-the-shelf optimization methods such as Limited memory BFGS (L-BFGS)
	and Conjugate gradient (CG) with line search can significantly simplify
	and speed up the process of pretraining deep algorithms. In our experiments,
	the difference between L-BFGS/CG and SGDs are more pronounced if
	we consider algorithmic extensions (e.g., sparsity regularization)
	and hardware extensions (e.g., GPUs or computer clusters). Our experiments
	with distributed optimization support the use of L-BFGS with locally
	connected networks and convolutional neural networks. Using L-BFGS,
	our convolutional network model achieves 0.69% on the standard MNIST
	dataset. This is a state-of-the-art result on MNIST among algorithms
	that do not use distortions or pretraining. Copyright 2011 by the
	author(s)/owner(s).},
  isbn = {9781450306195},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053437034&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Le2011b,
  author = {Le, Quoc V. and Zou, Will Y. and Yeung, Serena Y. and Ng, Andrew
	Y.},
  title = {{Learning hierarchical invariant spatio-temporal features for action
	recognition with independent subspace analysis}},
  booktitle = {CVPR 2011},
  year = {2011},
  pages = {3361--3368},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {Previous work on action recognition has focused on adapting hand-designed
	local features, such as SIFT or HOG, from static images to the video
	domain. In this paper, we propose using unsupervised feature learning
	as a way to learn features directly from video data. More specifically,
	we present an extension of the Independent Subspace Analysis algorithm
	to learn invariant spatio-temporal features from unlabeled video
	data. We discovered that, despite its simplicity, this method performs
	surprisingly well when combined with deep learning techniques such
	as stacking and convolution to learn hierarchical representations.
	By replacing hand-designed features with our learned features, we
	achieve classification results superior to all previous published
	results on the Hollywood2, UCF, KTH and YouTube action recognition
	datasets. On the challenging Hollywood2 and YouTube action datasets
	we obtain 53.3% and 75.8% respectively, which are approximately 5%
	better than the current best published results. Further benefits
	of this method, such as the ease of training and the efficiency of
	training and prediction, will also be discussed. You can download
	our code and learned spatio-temporal features here: http://ai.stanford.edu/wzou/
	© 2011 IEEE.},
  doi = {10.1109/CVPR.2011.5995496},
  isbn = {978-1-4577-0394-2},
  issn = {10636919},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052874098&partnerID=tZOtx3y1}
}

@ARTICLE{LeCun1990,
  author = {{LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard},
	L. D. Jackel},
  title = {{Handwritten Digit Recognition with a Back-Propagation Network}},
  journal = {Adv. Neural Inf. Process. Syst.},
  year = {1990},
  pages = {396--404},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard_1990_Handwritten Digit Recognition with a Back-Propagation Network.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076}
}

@ARTICLE{LeCun1998,
  author = {LeCun, Yann and Bengio, Yoshua},
  title = {{Convolutional networks for images, speech, and time series}},
  year = {1998},
  pages = {255--258},
  month = {\#oct\#},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, Bengio_1998_Convolutional networks for images, speech, and time series.pdf:pdf},
  isbn = {0-262-51102-9},
  publisher = {MIT Press},
  url = {http://dl.acm.org/citation.cfm?id=303568.303704}
}

@ARTICLE{LeCun1989,
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard,
	R. E. and Hubbard, W. and Jackel, L. D.},
  title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
  journal = {Neural Comput.},
  year = {1989},
  volume = {1},
  pages = {541--551},
  number = {4},
  month = {\#dec\#},
  abstract = {The ability of learning networks to generalize can be greatly enhanced
	by providing constraints from the task domain. This paper demonstrates
	how such constraints can be integrated into a backpropagation network
	through the architecture of the network. This approach has been successfully
	applied to the recognition of handwritten zip code digits provided
	by the U.S. Postal Service. A single network learns the entire recognition
	operation, going from the normalized image of the character to the
	final classification.},
  doi = {10.1162/neco.1989.1.4.541},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1989_Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
  issn = {0899-7667},
  keywords = {CNN},
  language = {en},
  mendeley-tags = {CNN},
  publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541#.VOiy7DTkdNo}
}

@ARTICLE{LeCun1998a,
  author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  title = {{Gradient-based learning applied to document recognition}},
  journal = {Proc. IEEE},
  year = {1998},
  volume = {86},
  pages = {2278--2324},
  number = {11},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm
	constitute the best example of a successful gradient based learning
	technique. Given an appropriate network architecture, gradient-based
	learning algorithms can be used to synthesize a complex decision
	surface that can classify high-dimensional patterns, such as handwritten
	characters, with minimal preprocessing. This paper reviews various
	methods applied to handwritten character recognition and compares
	them on a standard handwritten digit recognition task. Convolutional
	neural networks, which are specifically designed to deal with the
	variability of 2D shapes, are shown to outperform all other techniques.
	Real-life document recognition systems are composed of multiple modules
	including field extraction, segmentation recognition, and language
	modeling. A new learning paradigm, called graph transformer networks
	(GTN), allows such multimodule systems to be trained globally using
	gradient-based methods so as to minimize an overall performance measure.
	Two systems for online handwriting recognition are described. Experiments
	demonstrate the advantage of global training, and the flexibility
	of graph transformer networks. A graph transformer network for reading
	a bank cheque is also described. It uses convolutional neural network
	character recognizers combined with global training techniques to
	provide record accuracy on business and personal cheques. It is deployed
	commercially and reads several million cheques per day},
  doi = {10.1109/5.726791},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1998_Gradient-based learning applied to document recognition.pdf:pdf},
  issn = {00189219},
  keywords = {2D shape variability,Character recognition,Feature extraction,GTN,Hidden
	Markov models,Machine learning,Multi-layer neural network,Neural
	networks,Optical character recognition software,Optical computing,Pattern
	recognition,Principal component analysis,back-propagation,backpropagation,cheque
	reading,complex decision surface synthesis,convolution,convolutional
	neural network character recognizers,document recognition,document
	recognition systems,field extraction,gradient based learning technique,gradient-based
	learning,graph transformer networks,handwritten character recognition,handwritten
	digit recognition task,high-dimensional patterns,language modeling,multilayer
	neural networks,multilayer perceptrons,multimodule systems,optical
	character recognition,performance measure minimization,segmentation
	recognition},
  shorttitle = {Proceedings of the IEEE},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=726791}
}

@INPROCEEDINGS{Lee2011,
  author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew
	Y.},
  title = {{Unsupervised learning of hierarchical representations with convolutional
	deep belief networks}},
  booktitle = {Commun. ACM},
  year = {2009},
  volume = {54},
  number = {10},
  pages = {1--8},
  address = {New York, New York, USA},
  month = {\#jun\#},
  publisher = {ACM Press},
  abstract = {There has been much interest in unsupervised learning of hierarchical
	generative models such as deep belief networks. Scaling such models
	to full-sized, high-dimensional images remains a difficult problem.
	To address this problem, we present the convolutional deep belief
	network, a hierarchical generative model which scales to realistic
	image sizes. This model is translation-invariant and supports efficient
	bottom-up and top-down probabilistic inference. Key to our approach
	is probabilistic max-pooling, a novel technique which shrinks the
	representations of higher layers in a probabilistically sound way.
	Our experiments show that the algorithm learns useful high-level
	visual features, such as object parts, from unlabeled images of objects
	and natural scenes. We demonstrate excellent performance on several
	visual recognition tasks and show that our model can perform hierarchical
	(bottom-up and top-down) inference over full-sized images.},
  doi = {10.1145/2001269.2001295},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised learning of hierarchical representations with convolutional deep belief networks.pdf:pdf},
  isbn = {9781605585161},
  issn = {00010782},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053540444&partnerID=tZOtx3y1 http://www.scopus.com/inward/record.url?eid=2-s2.0-71149119164&partnerID=tZOtx3y1 http://dl.acm.org/citation.cfm?id=1553374.1553453}
}

@MISC{Lee,
  author = {Lee, H. and Largman, Y. and Pham, P. and Ng, A.Y.},
  title = {{Unsupervised feature learning for audio classification using convolutional
	deep belief networks}},
  booktitle = {NIPS},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956502334&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Lee2009a,
  author = {Lee, Honglak and Yan, Largman and Pham, Peter and Ng, Andrew Y. and
	Largman, Yan and Ng, Andrew Y.},
  title = {{Unsupervised feature learning for audio classification using convolutional
	deep belief networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2009},
  pages = {1096--1104},
  abstract = {In recent years, deep learning approaches have gained significant
	interest as a way of building hierarchical representations from unlabeled
	data. However, to our knowledge, these deep learning approaches have
	not been extensively studied for auditory data. In this paper, we
	apply convolutional deep belief networks to audio data and empirically
	evaluate them on various audio classification tasks. In the case
	of speech data, we show that the learned features correspond to phones/phonemes.
	In addition, our feature representations learned from unlabeled audio
	data show very good performance for multiple audio classification
	tasks. We hope that this paper will inspire more research on deep
	learning approaches applied to a wide range of audio recognition
	tasks.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised feature learning for audio classification using convolutional deep belief networks.pdf:pdf},
  isbn = {9781615679119},
  keywords = {CNN,Sound,Unsupervised},
  mendeley-tags = {CNN,Sound,Unsupervised},
  url = {http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for http://www.scopus.com/inward/record.url?eid=2-s2.0-84863380535&partnerID=tZOtx3y1}
}

@ARTICLE{Lehman2014,
  author = {Lehman, Joel and Clune, Jeff and Risi, Sebastian},
  title = {{An Anarchy of Methods: Current Trends in How Intelligence Is Abstracted
	in AI}},
  journal = {Intell. Syst. IEEE},
  year = {2014},
  volume = {29},
  pages = {56--62},
  number = {6},
  month = {\#nov\#},
  abstract = {Artificial intelligence (AI) is a sprawling field encompassing a diversity
	of approaches to machine intelligence and disparate perspectives
	on how intelligence should be viewed. Because researchers often engage
	only within their own specialized area of AI, there are many interesting
	broad questions about AI as a whole that often go unanswered. How
	should intelligence be abstracted in AI research? Which subfields,
	techniques, and abstractions are most promising? Why do researchers
	bet their careers on the particular abstractions and techniques of
	their chosen subfield of AI? Should AI research be "bio-inspired"
	and remain faithful to the process that produced intelligence (evolution)
	or the biological substrate that enables it (networks of neurons)?
	Discussing these big-picture questions motivated us to organize an
	AAAI Fall Symposium, which gathered participants across AI subfields
	to present and debate their views. This article distills the resulting
	insights.},
  doi = {10.1109/MIS.2014.92},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lehman, Clune, Risi_2014_An Anarchy of Methods Current Trends in How Intelligence Is Abstracted in AI.pdf:pdf},
  issn = {1541-1672},
  keywords = {AI,AI abstraction,AI research,AI subfields,AI techniques,Adaptive
	systems,Artificial intelligence,Biological system modeling,Brain
	modeling,Computational modeling,Design methodology,Neural networks,Neuroscience,Robots,adaptive
	systems,artificial intelligence,bio-inspired research,cognitive science,computational
	neuroscience,deep learning,design automation,developmental robotics,evolving
	neural networks,intelligent systems,machine intelligence,neuroevolution},
  shorttitle = {Intelligent Systems, IEEE},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6982117 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982117}
}

@ARTICLE{Li2009,
  author = {Li, Wei and Canini, Marco and Moore, Andrew W. and Bolla, Raffaele},
  title = {{Efficient application identification and the temporal and spatial
	stability of classification schema}},
  journal = {Comput. Networks},
  year = {2009},
  volume = {53},
  pages = {790--809},
  number = {6},
  month = {\#apr\#},
  abstract = {Motivated by the importance of accurate identification for a range
	of applications, this paper compares and contrasts the effective
	and efficient classification of network-based applications using
	behavioral observations of network-traffic and those using deep-packet
	inspection. Importantly, throughout our work we are able to make
	comparison with data possessing an accurate, independently determined
	ground-truth that describes the actual applications causing the network-traffic
	observed. In a unique study in both the spatial-domain: comparing
	across different network-locations and in the temporal-domain: comparing
	across a number of years of data, we illustrate the decay in classification
	accuracy across a range of application-classification mechanisms.
	Further, we document the accuracy of spatial classification without
	training data possessing spatial diversity. Finally, we illustrate
	the classification of UDP traffic. We use the same classification
	approach for both stateful flows (TCP) and stateless flows based
	upon UDP. Importantly, we demonstrate high levels of accuracy: greater
	than 92% for the worst circumstance regardless of the application.
	© 2008 Elsevier B.V. All rights reserved.},
  doi = {10.1016/j.comnet.2008.11.016},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Li et al._2009_Efficient application identification and the temporal and spatial stability of classification schema.pdf:pdf},
  issn = {13891286},
  keywords = {Application identification,Deep-packet inspection,Machine learning,Spatial
	stability,Temporal decay,Traffic classification},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-61749100211&partnerID=tZOtx3y1}
}

@ARTICLE{Marinai2005,
  author = {Marinai, Simone and Gori, Marco and Soda, Giovanni and Society, Computer},
  title = {{Artificial neural networks for document analysis and recognition.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2005},
  volume = {27},
  pages = {23--35},
  number = {1},
  month = {\#jan\#},
  abstract = {Artificial neural networks have been extensively applied to document
	analysis and recognition. Most efforts have been devoted to the recognition
	of isolated handwritten and printed characters with widely recognized
	successful results. However, many other document processing tasks,
	like preprocessing, layout analysis, character segmentation, word
	recognition, and signature verification, have been effectively faced
	with very promising results. This paper surveys the most significant
	problems in the area of offline document image processing, where
	connectionist-based approaches have been applied. Similarities and
	differences between approaches belonging to different categories
	are discussed. A particular emphasis is given on the crucial role
	of prior knowledge for the conception of both appropriate architectures
	and learning algorithms. Finally, the paper provides a critical analysis
	on the reviewed approaches and depicts the most promising research
	guidelines in the field. In particular, a second generation of connectionist-based
	models are foreseen which are based on appropriate graphical representations
	of the learning environment.},
  doi = {10.1109/TPAMI.2005.4},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Marinai et al._2005_Artificial neural networks for document analysis and recognition.pdf:pdf},
  issn = {0162-8828},
  keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Automatic
	Data Processing,Automatic Data Processing: methods,Computer Graphics,Computer-Assisted,Computer-Assisted:
	methods,Documentation,Handwriting,Image Enhancement,Image Enhancement:
	methods,Image Interpretation,Information Storage and Retrieval,Information
	Storage and Retrieval: methods,Neural Networks (Computer),Numerical
	Analysis,Pattern Recognition,Reading,Reproducibility of Results,Sensitivity
	and Specificity,Signal Processing,User-Computer Interface},
  pmid = {15628266},
  shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/15628266}
}

@INPROCEEDINGS{Martens2010,
  author = {Martens, James},
  title = {{Deep learning via Hessian-free optimization}},
  booktitle = {ICML 2010 - Proceedings, 27th Int. Conf. Mach. Learn.},
  year = {2010},
  pages = {735--742},
  abstract = {We develop a 2 nd-order optimization method based on the "Hessian-free"
	approach, and apply it to training deep auto-encoders. Without using
	pre-training, we obtain results superior to those reported by Hinton
	& Salakhutdinov (2006) on the same tasks they considered. Our method
	is practical, easy to use, scales nicely to very large datasets,
	and isn't limited in applicability to auto-encoders, or any specific
	model class. We also discuss the issue of "pathological curvature"
	as a possible explanation for the difficulty of deep-learning and
	how 2 nd-order optimization, and our method in particular, effectively
	deals with it. Copyright 2010 by the author(s)/owner(s).},
  isbn = {9781605589077},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956541496&partnerID=tZOtx3y1}
}

@ARTICLE{Merlo2001,
  author = {Merlo, Paola and Stevenson, Suzanne},
  title = {{Automatic Verb Classification Based on Statistical Distributions
	of Argument Structure}},
  journal = {Comput. Linguist.},
  year = {2001},
  volume = {27},
  pages = {373--408},
  number = {3},
  month = {\#sep\#},
  abstract = {Automatic acquisition of lexical knowledge is critical to a wide range
	of natural language processing tasks. Especially important is knowledge
	about verbs, which are the primary source of relational information
	in a sentence - the predicate-argument structure that relates an
	action or state to its participants (i.e., who did what to whom).
	In this work, we report on supervised learning experiments to automatically
	classify three major types of English verbs, based on their argument
	structure - specifically, the thematic roles they assign to participants.
	We use linguistically-motivated statistical indicators extracted
	from large annotated corpora to train the classifier, achieving 69.8%
	accuracy for a task whose baseline is 34%, and whose expert-based
	upper bound we calculate at 86.5%. A detailed analysis of the performance
	of the algorithm and of its errors confirms that the proposed features
	capture properties related to the argument structure of the verbs.
	Our results validate our hypotheses that knowledge about thematic
	relations is crucial for verb classification, and that it can be
	gleaned from a corpus by automatic means. We thus demonstrate an
	effective combination of deeper linguistic knowledge with the robustness
	and scalability of statistical techniques.},
  doi = {10.1162/089120101317066122},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Merlo, Stevenson_2001_Automatic Verb Classification Based on Statistical Distributions of Argument Structure.pdf:pdf},
  issn = {0891-2017},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0039190150&partnerID=tZOtx3y1}
}

@ARTICLE{Mierswa2005,
  author = {Mierswa, Ingo and Morik, Katharina},
  title = {{Automatic Feature Extraction for Classifying Audio Data}},
  journal = {Mach. Learn.},
  year = {2005},
  volume = {58},
  pages = {127--149},
  number = {2-3},
  month = {\#feb\#},
  abstract = {Today many private households as well as broadcasting or film companies
	own large collections of digital music plays. These are time series
	that differ from e.g. weather reports or stocks market data. The
	task is normally that of classification not prediction of the next
	value or recognizing a shape or motif. New methods for extracting
	features that allow to classify audio data have been developed. However
	the development of appropriate feature extraction methods is a tedious
	effort particularly because every new classification task requires
	tailoring the feature set anew. This paper presents a unifying framework
	for feature extraction from value series. Operators of this framework
	can be combined to feature extraction methods automatically using
	a genetic programming approach. The construction of features is guided
	by the performance of the learning classifier which uses the features.
	Our approach to automatic feature extraction requires a balance between
	the completeness of the methods on one side and the tractability
	of searching for appropriate methods on the other side. In this paper
	some theoretical considerations illustrate the trade-off. After the
	feature extraction a second process learns a classifier from the
	transformed data. The practical use of the methods is shown by two
	types of experiments: classification of genres and classification
	according to user preferences. © 2005 Springer Science + Business
	Media Inc.},
  doi = {10.1007/s10994-005-5824-7},
  issn = {0885-6125},
  keywords = {Analysis of audio data,Feature extraction,Music recommender systems,Time
	series transformations},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-15544385732&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Mobahi2009,
  author = {Mobahi, Hossein and Collobert, Ronan and Weston, Jason},
  title = {{Deep learning from temporal coherence in video}},
  booktitle = {Proc. 26th Int. Conf. Mach. Learn. ICML 2009},
  year = {2009},
  pages = {737--744},
  abstract = {This work proposes a learning method for deep architectures that takes
	advantage of sequential data, in particular from the temporal coherence
	that naturally exists in unlabeled video recordings. That is, two
	successive frames are likely to contain the same object or objects.
	This coherence is used as a supervisory signal over the unlabeled
	data, and is used to improve the performance on a supervised task
	of interest. We demonstrate the effectiveness of this method on some
	pose invariant object and face recognition tasks.},
  isbn = {9781605585161},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-71149084945&partnerID=tZOtx3y1}
}

@ARTICLE{Mohamed2012,
  author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
  title = {{Acoustic Modeling Using Deep Belief Networks}},
  journal = {IEEE Trans. Audio. Speech. Lang. Processing},
  year = {2012},
  volume = {20},
  pages = {14--22},
  number = {1},
  month = {\#jan\#},
  abstract = {Gaussian mixture models are currently the dominant technique for modeling
	the emission distribution of hidden Markov models for speech recognition.
	We show that better phone recognition on the TIMIT dataset can be
	achieved by replacing Gaussian mixture models by deep neural networks
	that contain many layers of features and a very large number of parameters.
	These networks are first pre-trained as a multi-layer generative
	model of a window of spectral feature vectors without making use
	of any discriminative information. Once the generative pre-training
	has designed the features, we perform discriminative fine-tuning
	using backpropagation to adjust the features slightly to make them
	better at predicting a probability distribution over the states of
	monophone hidden Markov models.},
  doi = {10.1109/TASL.2011.2109382},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton_2012_Acoustic Modeling Using Deep Belief Networks.pdf:pdf},
  issn = {1558-7916},
  keywords = {Acoustic modeling,Artificial neural networks,Computational modeling,DBN,Data
	models,Gaussian mixture models,Hidden Markov models,Speech,Speech
	recognition,TIMIT dataset,Training,acoustic modeling,backpropagation,belief
	networks,deep belief networks (DBNs),discriminative fine-tuning,emission
	distribution,hidden Markov models,monophone hidden Markov models,multilayer
	generative model,neural nets,neural networks,phone recognition,probability
	distribution,spectral feature vectors,speech recognition,statistical
	distributions},
  mendeley-tags = {DBN},
  shorttitle = {Audio, Speech, and Language Processing, IEEE Trans},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5704567}
}

@ARTICLE{Mohamed2012a,
  author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
  title = {{Acoustic Modeling Using Deep Belief Networks}},
  journal = {IEEE Trans. Audio. Speech. Lang. Processing},
  year = {2012},
  volume = {20},
  pages = {14--22},
  number = {1},
  month = {\#jan\#},
  abstract = {Gaussian mixture models are currently the dominant technique for modeling
	the emission distribution of hidden Markov models for speech recognition.
	We show that better phone recognition on the TIMIT dataset can be
	achieved by replacing Gaussian mixture models by deep neural networks
	that contain many layers of features and a very large number of parameters.
	These networks are first pre-trained as a multi-layer generative
	model of a window of spectral feature vectors without making use
	of any discriminative information. Once the generative pre-training
	has designed the features, we perform discriminative fine-tuning
	using backpropagation to adjust the features slightly to make them
	better at predicting a probability distribution over the states of
	monophone hidden Markov models. © 2011 IEEE.},
  doi = {10.1109/TASL.2011.2109382},
  issn = {1558-7916},
  keywords = {Acoustic modeling,deep belief networks (DBNs),neural networks,phone
	recognition},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84055211743&partnerID=tZOtx3y1}
}

@ARTICLE{Morgan1995,
  author = {Morgan, N. and Bourlard, H.},
  title = {{Continuous speech recognition}},
  journal = {IEEE Signal Process. Mag.},
  year = {1995},
  volume = {12},
  pages = {24--42},
  number = {3},
  month = {\#may\#},
  abstract = {The HMM/connectionist approach to large vocabulary continuous speech
	recognition, as the name implies, is a cross between the statistical
	representations called hidden Markov models and artificial neural
	network methods. This approach provides a mechanism for incorporating
	a range of sources of evidence without strong assumptions about their
	joint statistics, and may have applicability to much more complex
	systems that can incorporate deep acoustic and linguistic context.
	The method is intrinsically discriminant and conservative of parameters.},
  doi = {10.1109/79.382443},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Morgan, Bourlard_1995_Continuous speech recognition.pdf:pdf},
  issn = {10535888},
  publisher = {IEEE},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0029306621&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Nair2009,
  author = {Nair, Vinod and Hinton, Geoffrey E.},
  title = {{3D object recognition with Deep Belief Nets}},
  booktitle = {Adv. Neural Inf. Process. Syst. 22 - Proc. 2009 Conf.},
  year = {2009},
  pages = {1339--1347},
  abstract = {We introduce a new type of top-level model for Deep Belief Nets and
	evaluate it on a 3D object recognition task. The top-level model
	is a third-order Boltzmann machine, trained using a hybrid algorithm
	that combines both generative and discriminative gradients. Performance
	is evaluated on the NORB database (normalized-uniform version), which
	contains stereo-pair images of objects under different lighting conditions
	and viewpoints. Our model achieves 6.5% error on the test set, which
	is close to the best published result for NORB (5.9%) using a convolutional
	neural net that has built-in knowledge of translation invariance.
	It substantially outperforms shallow models such as SVMs (11.6%).
	DBNs are especially suited for semi-supervised learning, and to demonstrate
	this we consider a modified version of the NORB recognition task
	in which additional unlabeled images are created by applying small
	translations to the images in the database. With the extra unlabeled
	data (and the same amount of labeled data as before), our model achieves
	5.2% error.},
  isbn = {9781615679119},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149306047&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Ngiam2011a,
  author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and
	Lee, Honglak and Ng, Andrew Y.},
  title = {{Multimodal Deep Learning}},
  booktitle = {Proc. 28th Int. Conf. Mach. Learn.},
  year = {2011},
  pages = {689--696},
  abstract = {Deep networks have been successfully applied to unsupervised feature
	learning for single modalities (e.g., text, images or audio). In
	this work, we propose a novel application of deep networks to learn
	features over multiple modalities. We present a series of tasks for
	multimodal learning and show how to train deep networks that learn
	features to address these tasks. In particular, we demonstrate cross
	modality feature learning, where better features for one modality
	(e.g., video) can be learned ifmultiple modalities (e.g., audio and
	video) are present at feature learning time. Furthermore, we show
	how to learn a shared representation between modalities and evalu-
	ate it on a unique task, where the classifier is trained with audio-only
	data but tested with video-only data and vice-versa. Our mod- els
	are validated on the CUAVE and AVLet- ters datasets on audio-visual
	speech classifi- cation, demonstrating best published visual speech
	classification on AVLetters and effec- tive shared representation
	learning.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ngiam et al._2011_Multimodal Deep Learning.pdf:pdf},
  isbn = {9781450306195},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053437179&partnerID=tZOtx3y1}
}

@ARTICLE{Pang2008,
  author = {Pang, B and Lee, L},
  title = {{Opinion mining and sentiment analysis}},
  journal = {Found. trends Inf. Retr.},
  year = {2008},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Pang, Lee_2008_Opinion mining and sentiment analysis.pdf:pdf},
  url = {http://dl.acm.org/citation.cfm?id=1454712}
}

@ARTICLE{Pradhan2005,
  author = {Pradhan, Sameer and Hacioglu, Kadri and Krugler, Valerie and Ward,
	Wayne and Martin, James H. and Jurafsky, Daniel},
  title = {{Support Vector Learning for Semantic Argument Classification}},
  journal = {Mach. Learn.},
  year = {2005},
  volume = {60},
  pages = {11--39},
  number = {1-3},
  month = {\#jun\#},
  abstract = {The natural language processing community has recently experienced
	a growth of interest in domain independent shallow semantic parsing-the
	process of assigning a Who did What to Whom, When, Where, Why, How
	etc. structure to plain text. This process entails identifying groups
	of words in a sentence that represent these semantic arguments and
	assigning specific labels to them. It could play a key role in NLP
	tasks like Information Extraction, Question Answering and Summarization.
	We propose a machine learning algorithm for semantic role parsing,
	extending the work of Gildea and Jurafsky (2002), Surdeanu et al.
	(2003) and others. Our algorithm is based on Support Vector Machines
	which we show give large improvement in performance over earlier
	classifiers. We show performance improvements through a number of
	new features designed to improve generalization to unseen data, such
	as automatic clustering of verbs. We also report on various analytic
	studies examining which features are most important, comparing our
	classifier to other machine learning algorithms in the literature,
	and testing its generalization to new test set from different genre.
	On the task of assigning semantic labels to the PropBank (Kingsbury,
	Palmer, & Marcus, 2002) corpus, our final system has a precision
	of 84% and a recall of 75%, which are the best results currently
	reported for this task. Finally, we explore a completely different
	architecture which does not requires a deep syntactic parse. We reformulate
	the task as a combined chunking and classification problem, thus
	allowing our algorithm to be applied to new languages or genres of
	text for which statistical syntactic parsers may not be available.},
  doi = {10.1007/s10994-005-0912-2},
  issn = {0885-6125},
  keywords = {Shallow semantic parsing,Support vector machines},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-24044446171&partnerID=tZOtx3y1}
}

@ARTICLE{QuocV.Le,
  author = {{Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado,
	Jeff Dean}, Andrew Y. Ng},
  title = {{Building high-level features using large scale unsupervised learning}},
  journal = {Int. Conf. Mach. Learn.},
  year = {2012},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean_2012_Building high-level features using large scale unsupe.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.261.605}
}

@INPROCEEDINGS{Raina2009,
  author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
  title = {{Large-scale deep unsupervised learning using graphics processors}},
  booktitle = {Proc. 26th Int. Conf. Mach. Learn. ICML 2009},
  year = {2009},
  pages = {873--880},
  abstract = {The promise of unsupervised learning methods lies in their potential
	to use vast amounts of unlabeled data to learn complex, highly nonlinear
	models with millions of free parameters. We consider two well-known
	unsupervised learning models, deep belief networks (DBNs) and sparse
	coding, that have recently been applied to a flurry of machine learning
	applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007).
	Unfortunately, current learning algorithms for both models are too
	slow for large-scale applications, forcing researchers to focus on
	smaller-scale models, or to use fewer training examples. In this
	paper, we suggest massively parallel methods to help resolve these
	problems. We argue that modern graphics processors far surpass the
	computational capabilities of multicore CPUs, and have the potential
	to revolutionize the applicability of deep unsupervised learning
	methods. We develop general principles for massively parallelizing
	unsupervised learning tasks using graphics processors. We show that
	these principles can be applied to successfully scaling up learning
	algorithms for both DBNs and sparse coding. Our implementation of
	DBN learning is up to 70 times faster than a dual-core CPU implementation
	for large models. For example, we are able to reduce the time required
	to learn a four-layer DBN with 100 million free parameters from several
	weeks to around a single day. For sparse coding, we develop a simple,
	inherently parallel algorithm, that leads to a 5 to 15-fold speedup
	over previous methods.},
  isbn = {9781605585161},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-71149105669&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Ranzato2008,
  author = {Ranzato, Marc'aurelio and Boureau, Y-lan and Cun, Yann L.},
  title = {{Sparse Feature Learning for Deep Belief Networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2008},
  pages = {1185--1192},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato, Boureau, Cun_2008_Sparse Feature Learning for Deep Belief Networks.pdf:pdf},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://papers.nips.cc/paper/3363-sparse-feature-learning-for-deep-belief-networks}
}

@INPROCEEDINGS{Ranzato2011,
  author = {Ranzato, Marc'Aurelio and Susskind, Joshua and Mnih, Volodymyr and
	Hinton, Geoffrey},
  title = {{On deep generative models with applications to recognition}},
  booktitle = {CVPR 2011},
  year = {2011},
  pages = {2857--2864},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {The most popular way to use probabilistic models in vision is first
	to extract some descriptors of small image patches or object parts
	using well-engineered features, and then to use statistical learning
	tools to model the dependencies among these features and eventual
	labels. Learning probabilistic models directly on the raw pixel values
	has proved to be much more difficult and is typically only used for
	regularizing discriminative methods. In this work, we use one of
	the best, pixel-level, generative models of natural images-a gated
	MRF-as the lowest level of a deep belief network (DBN) that has several
	hidden layers. We show that the resulting DBN is very good at coping
	with occlusion when predicting expression categories from face images,
	and it can produce features that perform comparably to SIFT descriptors
	for discriminating different types of scene. The generative ability
	of the model also makes it easy to see what information is captured
	and what is lost at each level of representation. © 2011 IEEE.},
  doi = {10.1109/CVPR.2011.5995710},
  isbn = {978-1-4577-0394-2},
  issn = {10636919},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052877144&partnerID=tZOtx3y1}
}

@ARTICLE{Rodd2004,
  author = {Rodd, J},
  title = {{Modelling the effects of semantic ambiguity in word recognition}},
  journal = {Cogn. Sci.},
  year = {2004},
  volume = {28},
  pages = {89--104},
  number = {1},
  month = {\#feb\#},
  abstract = {Most words in English are ambiguous between different interpretations;
	words can mean different things in different contexts. We investigate
	the implications of different types of semantic ambiguity for connectionist
	models of word recognition. We present a model in which there is
	competition to activate distributed semantic representations. The
	model performs well on the task of retrieving the different meanings
	of ambiguous words, and is able to simulate data reported by Rodd,
	Gaskell, and Marslen-Wilson [J. Mem. Lang. 46 (2002) 245] on how
	semantic ambiguity affects lexical decision performance. In particular,
	the network shows a disadvantage for words with multiple unrelated
	meanings (e.g., bark) that coexists with a benefit for words with
	multiple related word senses (e.g., twist). The ambiguity disadvantage
	arises because of interference between the different meanings, while
	the sense benefit arises because of differences in the structure
	of the attractor basins formed during learning. Words with few senses
	develop deep, narrow attractor basins, while words with many senses
	develop shallow, broad basins. We conclude that the mental representations
	of word meanings can be modelled as stable states within a high-dimensional
	semantic space, and that variations in the meanings of words shape
	the landscape of this space. © 2003 Cognitive Science Society, Inc.
	All rights reserved.},
  doi = {10.1016/j.cogsci.2003.08.002},
  issn = {03640213},
  keywords = {Connectionist networks,Distributed representations,Lexical ambiguity,Lexical
	decision,Semantic ambiguity,Word recognition},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-1142303068&partnerID=tZOtx3y1}
}

@ARTICLE{Sabou2005,
  author = {Sabou, Marta and Wroe, Chris and Goble, Carole and Stuckenschmidt,
	Heiner},
  title = {{Learning domain ontologies for semantic Web service descriptions}},
  journal = {Web Semant. Sci. Serv. Agents World Wide Web},
  year = {2005},
  volume = {3},
  pages = {340--365},
  number = {4},
  month = {\#dec\#},
  abstract = {High quality domain ontologies are essential for successful employment
	of semantic Web services. However, their acquisition is difficult
	and costly, thus hampering the development of this field. In this
	paper we report on the first stage of research that aims to develop
	(semi-)automatic ontology learning tools in the context of Web services
	that can support domain experts in the ontology building task. The
	goal of this first stage was to get a better understanding of the
	problem at hand and to determine which techniques might be feasible
	to use. To this end, we developed a framework for (semi-)automatic
	ontology learning from textual sources attached to Web services.
	The framework exploits the fact that these sources are expressed
	in a specific sublanguage, making them amenable to automatic analysis.
	We implement two methods in this framework, which differ in the complexity
	of the employed linguistic analysis. We evaluate the methods in two
	different domains, verifying the quality of the extracted ontologies
	against high quality hand-built ontologies of these domains. Our
	evaluation lead to a set of valuable conclusions on which further
	work can be based. First, it appears that our method, while tailored
	for the Web services context, might be applicable across different
	domains. Second, we concluded that deeper linguistic analysis is
	likely to lead to better results. Finally, the evaluation metrics
	indicate that good results can be achieved using only relatively
	simple, off the shelf techniques. Indeed, the novelty of our work
	is not in the used natural language processing methods but rather
	in the way they are put together in a generic framework specialized
	for the context of Web services. © 2005 Elsevier B.V. All rights
	reserved.},
  doi = {10.1016/j.websem.2005.09.008},
  issn = {15708268},
  keywords = {Ontology learning,Ontology learning evaluation,Semantic Web services},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28044452224&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Sainath2012,
  author = {Sainath, Tara N. and Kingsbury, Brian and Ramabhadran, Bhuvana},
  title = {{Auto-encoder bottleneck features using deep belief networks}},
  booktitle = {2012 IEEE Int. Conf. Acoust. Speech Signal Process.},
  year = {2012},
  pages = {4153--4156},
  month = {\#mar\#},
  publisher = {IEEE},
  abstract = {Neural network (NN) bottleneck (BN) features are typically created
	by training a NN with a middle bottleneck layer. Recently, an alternative
	structure was proposed which trains a NN with a constant number of
	hidden units to predict output targets, and then reduces the dimensionality
	of these output probabilities through an auto-encoder, to create
	auto-encoder bottleneck (AE-BN) features. The benefit of placing
	the BN after the posterior estimation network is that it avoids the
	loss in frame classification accuracy incurred by networks that place
	the BN before the softmax. In this work, we investigate the use of
	pre-training when creating AE-BN features. Our experiments indicate
	that with the AE-BN architecture, pre-trained and deeper NNs produce
	better AE-BN features. On a 50-hour English Broadcast News task,
	the AE-BN features provide over a 1% absolute improvement compared
	to a state-of-the-art GMM/HMM with a WER of 18.8% and pre-trained
	NN hybrid system with a WER of 18.4%. In addition, on a larger 430-hour
	Broadcast News task, AE-BN features provide a 0.5% absolute improvement
	over a strong GMM/HMM baseline with a WER of 16.0%. Finally, system
	combination with the GMM/HMM baseline and AE-BN systems provides
	an additional 0.5% absolute on 430 hours over the AE-BN system alone,
	yielding a final WER of 15.0%. © 2012 IEEE.},
  doi = {10.1109/ICASSP.2012.6288833},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Sainath, Kingsbury, Ramabhadran_2012_Auto-encoder bottleneck features using deep belief networks.pdf:pdf},
  isbn = {978-1-4673-0046-9},
  issn = {15206149},
  keywords = {Deep Belief Networks,Speech Recognition},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867593213&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Salakhutdinov2010,
  author = {Salakhutdinov, Ruslan},
  title = {{Learning Deep Boltzmann Machines using adaptive MCMC}},
  booktitle = {ICML 2010 - Proceedings, 27th Int. Conf. Mach. Learn.},
  year = {2010},
  pages = {943--950},
  abstract = {When modeling high-dimensional richly structured data, it is often
	the case that the distribution defined by the Deep Boltzmann Machine
	(DBM) has a rough energy landscape with many local minima separated
	by high energy barriers. The commonly used Gibbs sampler tends to
	get trapped in one local mode, which often results in unstable learning
	dynamics and leads to poor parameter estimates. In this paper, we
	concentrate on learning DBM's using adaptive MCMC algorithms. We
	first show a close connection between Fast PCD and adaptive MCMC.
	We then develop a Coupled Adaptive Simulated Tempering algorithm
	that can be used to better explore a highly multimodal energy landscape.
	Finally, we demonstrate that the proposed algorithm considerably
	improves parameter estimates, particularly when learning large-scale
	DBM's. Copyright 2010 by the author(s)/owner(s).},
  isbn = {9781605589077},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956506016&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Salakhutdinov2009,
  author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
  title = {{Deep Boltzmann machines}},
  booktitle = {J. Mach. Learn. Res.},
  year = {2009},
  volume = {5},
  pages = {448--455},
  abstract = {We present a new learning algorithm for Boltzmann machines that contain
	many layers of hidden variables. Data-dependent expectations are
	estimated using a variational approximation that tends to focus on
	a single mode, and dataindependent expectations are approximated
	using persistent Markov chains. The use of two quite different techniques
	for estimating the two types of expectation that enter into the gradient
	of the log-likelihood makes it practical to learn Boltzmann machines
	with multiple hidden layers and millions of parameters. The learning
	can be made more efficient by using a layer-by-layer "pre-training"
	phase that allows variational inference to be initialized with a
	single bottomup pass. We present results on the MNIST and NORB datasets
	showing that deep Boltzmann machines learn good generative models
	and perform well on handwritten digit and visual object recognition
	tasks. © 2009 by the authors.},
  issn = {15324435},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862286946&partnerID=tZOtx3y1}
}

@ARTICLE{Salakhutdinov2009a,
  author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
  title = {{Semantic hashing}},
  journal = {Int. J. Approx. Reason.},
  year = {2009},
  volume = {50},
  pages = {969--978},
  number = {7},
  month = {\#jul\#},
  abstract = {We show how to learn a deep graphical model of the word-count vectors
	obtained from a large set of documents. The values of the latent
	variables in the deepest layer are easy to infer and give a much
	better representation of each document than Latent Semantic Analysis.
	When the deepest layer is forced to use a small number of binary
	variables (e.g. 32), the graphical model performs "semantic hashing":
	Documents are mapped to memory addresses in such a way that semantically
	similar documents are located at nearby addresses. Documents similar
	to a query document can then be found by simply accessing all the
	addresses that differ by only a few bits from the address of the
	query document. This way of extending the efficiency of hash-coding
	to approximate matching is much faster than locality sensitive hashing,
	which is the fastest current method. By using semantic hashing to
	filter the documents given to TF-IDF, we achieve higher accuracy
	than applying TF-IDF to the entire document set. © 2008 Elsevier
	Inc. All rights reserved.},
  doi = {10.1016/j.ijar.2008.11.006},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Hinton_2009_Semantic hashing.pdf:pdf},
  issn = {0888613X},
  keywords = {Graphical models,Information retrieval,Unsupervised learning},
  url = {http://www.sciencedirect.com/science/article/pii/S0888613X08001813 http://www.scopus.com/inward/record.url?eid=2-s2.0-67449128732&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Salakhutdinov2007a,
  author = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
  title = {{Restricted Boltzmann machines for collaborative filtering}},
  booktitle = {Proc. 24th Int. Conf. Mach. Learn. - ICML '07},
  year = {2007},
  pages = {791--798},
  address = {New York, New York, USA},
  month = {\#jun\#},
  publisher = {ACM Press},
  doi = {10.1145/1273496.1273596},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Mnih, Hinton_2007_Restricted Boltzmann machines for collaborative filtering.pdf:pdf},
  isbn = {9781595937933},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://dl.acm.org/citation.cfm?id=1273496.1273596}
}

@INPROCEEDINGS{Salakhutdinov2008,
  author = {Salakhutdinov, Ruslan and Murray, Iain},
  title = {{On the quantitative analysis of deep belief networks}},
  booktitle = {Proc. 25th Int. Conf. Mach. Learn.},
  year = {2008},
  pages = {872--879},
  abstract = {Deep Belief Networks (DBN's) are generative models that contain many
	layers of hidden variables. Efficient greedy algorithms for learning
	and approximate inference have allowed these models to be applied
	successfully in many application domains. The main building block
	of a DBN is a bipartite undirected graphical model called a restricted
	Boltzmann machine (RBM). Due to the presence of the partition function,
	model selection, complexity control, and exact maximum likelihood
	learning in RBM's are intractable. We show that Annealed Importance
	Sampling (AIS) can be used to efficiently estimate the partition
	function of an RBM, and we present a novel AIS scheme for comparing
	RBM's with different architectures. We further show how an AIS estimator,
	along with approximate inference, can be used to estimate a lower
	bound on the log-probability that a DBN model with multiple hidden
	layers assigns to the test data. This is, to our knowledge, the first
	step towards obtaining quantitative results that would allow us to
	directly assess the performance of Deep Belief Networks as generative
	models of data. Copyright 2008 by the author(s)/owner(s).},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Murray_2008_On the quantitative analysis of deep belief networks.pdf:pdf},
  isbn = {9781605582054},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449102578&partnerID=tZOtx3y1}
}

@ARTICLE{Schmidhuber2014,
  author = {Schmidhuber, Juergen},
  title = {{Deep Learning in Neural Networks: An Overview}},
  year = {2014},
  pages = {75},
  month = {\#apr\#},
  abstract = {In recent years, deep artificial neural networks (including recurrent
	ones) have won numerous contests in pattern recognition and machine
	learning. This historical survey compactly summarises relevant work,
	much of it from the previous millennium. Shallow and deep learners
	are distinguished by the depth of their credit assignment paths,
	which are chains of possibly learnable, causal links between actions
	and effects. I review deep supervised learning (also recapitulating
	the history of backpropagation), unsupervised learning, reinforcement
	learning & evolutionary computation, and indirect search for short
	programs encoding deep and large networks.},
  archiveprefix = {arXiv},
  arxivid = {1404.7828},
  eprint = {1404.7828},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Schmidhuber_2014_Deep Learning in Neural Networks An Overview.pdf:pdf},
  url = {http://arxiv.org/abs/1404.7828}
}

@MISC{Seeger2004,
  author = {Seeger, Matthias},
  title = {{Gaussian processes for machine learning.}},
  year = {2004},
  abstract = {Gaussian processes (GPs) are natural generalisations of multivariate
	Gaussian random variables to infinite (countably or continuous) index
	sets. GPs have been applied in a large number of fields to a diverse
	range of ends, and very many deep theoretical analyses of various
	properties are available. This paper gives an introduction to Gaussian
	processes on a fairly elementary level with special emphasis on characteristics
	relevant in machine learning. It draws explicit connections to branches
	such as spline smoothing models and support vector machines in which
	similar ideas have been investigated. Gaussian process models are
	routinely used to solve hard machine learning problems. They are
	attractive because of their flexible non-parametric nature and computational
	simplicity. Treated within a Bayesian framework, very powerful statistical
	methods can be implemented which offer valid estimates of uncertainties
	in our predictions and generic model selection procedures cast as
	nonlinear optimization problems. Their main drawback of heavy computational
	scaling has recently been alleviated by the introduction of generic
	sparse approximations.13,78,31 The mathematical literature on GPs
	is large and often uses deep concepts which are not required to fully
	understand most machine learning applications. In this tutorial paper,
	we aim to present characteristics of GPs relevant to machine learning
	and to show up precise connections to other "kernel machines" popular
	in the community. Our focus is on a simple presentation, but references
	to more detailed sources are provided.},
  booktitle = {Int. J. Neural Syst.},
  issn = {01290657},
  number = {2},
  pages = {69--106},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-12444291490&partnerID=tZOtx3y1},
  volume = {14}
}

@MISC{Seide,
  author = {Seide, F. and Li, G. and Yu, D.},
  title = {{Conversational speech transcription using context-dependent deep
	neural networks}},
  booktitle = {Proc. Interspeech},
  pages = {437--440},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858966230&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Simard2003,
  author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
  title = {{Best practices for convolutional neural networks applied to visual
	document analysis}},
  booktitle = {Seventh Int. Conf. Doc. Anal. Recognition, 2003. Proceedings.},
  year = {2003},
  volume = {1},
  pages = {958--963},
  publisher = {IEEE Comput. Soc},
  abstract = {Not Available},
  doi = {10.1109/ICDAR.2003.1227801},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Simard, Steinkraus, Platt_2003_Best practices for convolutional neural networks applied to visual document analysis.pdf:pdf},
  isbn = {0-7695-1960-1},
  keywords = {Best practices,CNN,Concrete,Convolution,Handwriting recognition,Industrial
	training,Information processing,Neural networks,Performance analysis,Support
	vector machines,Text analysis},
  mendeley-tags = {CNN},
  shorttitle = {Document Analysis and Recognition, 2003. Proceedin},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801}
}

@ARTICLE{Smith2006,
  author = {Smith, Evan C and Lewicki, Michael S},
  title = {{Efficient auditory coding.}},
  journal = {Nature},
  year = {2006},
  volume = {439},
  pages = {978--82},
  number = {7079},
  month = {\#feb\#},
  abstract = {The auditory neural code must serve a wide range of auditory tasks
	that require great sensitivity in time and frequency and be effective
	over the diverse array of sounds present in natural acoustic environments.
	It has been suggested that sensory systems might have evolved highly
	efficient coding strategies to maximize the information conveyed
	to the brain while minimizing the required energy and neural resources.
	Here we show that, for natural sounds, the complete acoustic waveform
	can be represented efficiently with a nonlinear model based on a
	population spike code. In this model, idealized spikes encode the
	precise temporal positions and magnitudes of underlying acoustic
	features. We find that when the features are optimized for coding
	either natural sounds or speech, they show striking similarities
	to time-domain cochlear filter estimates, have a frequency-bandwidth
	dependence similar to that of auditory nerve fibres, and yield significantly
	greater coding efficiency than conventional signal representations.
	These results indicate that the auditory code might approach an information
	theoretic optimum and that the acoustic structure of speech might
	be adapted to the coding capacity of the mammalian auditory system.},
  doi = {10.1038/nature04485},
  issn = {1476-4687},
  keywords = {Acoustic Stimulation,Adaptation, Physiological,Adaptation, Physiological:
	physiology,Algorithms,Animals,Auditory Perception,Auditory Perception:
	physiology,Cochlea,Cochlea: physiology,Hearing,Hearing: physiology,Humans,Models,
	Neurological,Noise,Sensitivity and Specificity,Sound,Speech,Speech:
	physiology,Time Factors},
  pmid = {16495999},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33644513420&partnerID=tZOtx3y1}
}

@ARTICLE{Srivastava2014,
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and
	Sutskever, Ilya and Salakhutdinov, Ruslan},
  title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
  journal = {J. Mach. Learn. Res.},
  year = {2014},
  volume = {15},
  pages = {1929--1958},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava et al._2014_Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
  url = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@INPROCEEDINGS{Srivastava2012,
  author = {Srivastava, Nitish and Salakhutdinov, Ruslan R.},
  title = {{Multimodal Learning with Deep Boltzmann Machines}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2012},
  pages = {2222--2230},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava, Salakhutdinov_2012_Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines}
}

@INPROCEEDINGS{Suchanek2006,
  author = {Suchanek, Fabian M. and Ifrim, Georgiana and Weikum, Gerhard},
  title = {{Combining linguistic and statistical analysis to extract relations
	from web documents}},
  booktitle = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
  year = {2006},
  volume = {2006},
  pages = {712--717},
  abstract = {The World Wide Web provides a nearly endless source of knowledge,
	which is mostly given in natural language. A first step towards exploiting
	this data automatically could be to extract pairs of a given semantic
	relation from text documents - for example all pairs of a person
	and her birth-date. One strategy for this task is to find text patterns
	that express the semantic relation, to generalize these patterns,
	and to apply them to a corpus to find new pairs. In this paper, we
	show that this approach profits significantly when deep linguistic
	structures are used instead of surface text patterns. We demonstrate
	how linguistic structures can be represented for machine learning,
	and we provide a theoretical analysis of the pattern matching approach.
	We show the benefits of our approach by extensive experiments with
	our prototype system LEILA. Copyright 2006 ACM.},
  isbn = {1595933395},
  keywords = {Machine Learning,Pattern Matching,Relation Extraction},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749565187&partnerID=tZOtx3y1}
}

@ARTICLE{Teh2006,
  author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei,
	David M},
  title = {{Hierarchical Dirichlet Processes}},
  journal = {J. Am. Stat. Assoc.},
  year = {2006},
  volume = {101},
  pages = {1566--1581},
  number = {476},
  month = {\#dec\#},
  abstract = {We consider problems involving groups of data where each observation
	within a group is a draw from a mixture model and where it is desirable
	to share mixture components between groups. We assume that the number
	of mixture components is unknown a priori and is to be inferred from
	the data. In this setting it is natural to consider sets of Dirichlet
	processes, one for each group, where the well-known clustering properly
	of the Dirichlet process provides a nonparametric prior for the number
	of mixture components within each group. Given our desire to tie
	the mixture models in the various groups, we consider a hierarchical
	model, specifically one in which the base measure for the child Dirichlet
	processes is itself distributed according to a Dirichlet process.
	Such a base measure being discrete, the child Dirichlet processes
	necessarily share atoms. Thus, as desired, the mixture models in
	the different groups necessarily share mixture components. We discuss
	representations of hierarchical Dirichlet processes in terms of a
	stick-breaking process, and a generalization of the Chinese restaurant
	process that we refer to as the "Chinese restaurant franchise." We
	present Markov chain Monte Carlo algorithms for posterior inference
	in hierarchical Dirichlet process mixtures and describe applications
	to problems in information retrieval and text modeling. © 2006 American
	Statistical Association.},
  doi = {10.1198/016214506000000302},
  issn = {0162-1459},
  keywords = {Clustering,Hierarchical model,Markov chain Monte Carlo,Mixture model,Nonparametric
	Bayesian statistics},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749249312&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Viaud2008,
  author = {Viaud, Marie-Luce and Thi\`{e}vre, J\'{e}r\"{o}me and Go\"{e}au,
	Herv\'{e} and Saulnier, Agnes and Buisson, Olivier},
  title = {{Interactive components for visual exploration of multimedia archives}},
  booktitle = {Proc. 2008 Int. Conf. Content-based image video Retr. - CIVR '08},
  year = {2008},
  pages = {609},
  address = {New York, New York, USA},
  publisher = {ACM Press},
  abstract = {With the increase of online resources, one main challenge for multimedia
	content providers is to provide efficient and user friendly tools
	for a deep and shallow navigation adapted to large scale audiovisual
	content. This paper describes a generic framework to build visual
	interactive applications the objectives of which are to enhance the
	understanding and to allow easy access to multimedia resources and
	management. Visual Maps are built on multi-modal similarity matrices
	computed from automatically extracted descriptors and use graph clustering
	and layout methods. Active relevance feedback methods are applied
	to allow users to control the maps evolution according to their needs.
	The First results of users' evaluation are presented for one of our
	tools. Copyright 2008 ACM.},
  doi = {10.1145/1386352.1386440},
  isbn = {9781605580708},
  keywords = {Active learning,Cross modal descriptors,Index structuring,Information
	visualization,Interactivity,Multimedia archives,Scalability},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57549087246&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Vincent2008,
  author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol,
	Pierre Antoine},
  title = {{Extracting and composing robust features with denoising autoencoders}},
  booktitle = {Proc. 25th Int. Conf. Mach. Learn.},
  year = {2008},
  pages = {1096--1103},
  abstract = {Previous work has shown that the difficulties in learning deep generative
	or discriminative models can be overcome by an initial unsupervised
	learning step that maps inputs to useful intermediate representations.
	We introduce and motivate a new training principle for unsupervised
	learning of a representation based on the idea of making the learned
	representations robust to partial corruption of the input pattern.
	This approach can be used to train autoencoders, and these denoising
	autoencoders can be stacked to initialize deep architectures. The
	algorithm can be motivated from a manifold learning and information
	theoretic perspective or from a generative model perspective. Comparative
	experiments clearly show the surprising advantage of corrupting the
	input of autoencoders on a pattern classification benchmark suite.
	Copyright 2008 by the author(s)/owner(s).},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2008_Extracting and composing robust features with denoising autoencoders.pdf:pdf},
  isbn = {9781605582054},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449089103&partnerID=tZOtx3y1}
}

@ARTICLE{Vincent2010a,
  author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio,
	Yoshua and Manzagol, Pierre-Antoine Antoine},
  title = {{Stacked Denoising Autoencoders: Learning Useful Representations
	in a Deep Network with a Local Denoising Criterion}},
  journal = {J. Mach. Learn. Res.},
  year = {2010},
  volume = {11},
  pages = {3371--3408},
  month = {\#mar\#},
  abstract = {We explore an original strategy for building deep networks, based
	on stacking layers of denoising autoencoders which are trained locally
	to denoise corrupted versions of their inputs. The resulting algorithm
	is a straightforward variation on the stacking of ordinary autoencoders.
	It is however shown on a benchmark of classification problems to
	yield significantly lower classification error, thus bridging the
	performance gap with deep belief networks (DBN), and in several cases
	surpassing it. Higher level representations learnt in this purely
	unsupervised fashion also help boost the performance of subsequent
	SVM classifiers. Qualitative experiments show that, contrary to ordinary
	autoencoders, denoising autoencoders are able to learn Gabor-like
	edge detectors from natural image patches and larger stroke detectors
	from digit images. This work clearly establishes the value of using
	a denoising criterion as a tractable unsupervised objective to guide
	the learning of useful higher level representations. © 2010.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2010_Stacked Denoising Autoencoders Learning Useful Representations in a Deep Network with a Local Denoising Criterion.pdf:pdf},
  issn = {15324435},
  keywords = {Autoencoders,Deep belief networks,Deep learning,Denoising,Unsupervised
	feature learning},
  publisher = {JMLR.org},
  url = {http://dl.acm.org/citation.cfm?id=1756006.1953039 http://www.scopus.com/inward/record.url?eid=2-s2.0-79551480483&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Weston2008,
  author = {Weston, Jason and Ratle, Fr\'{e}d\'{e}ric and Collobert, Ronan},
  title = {{Deep learning via semi-supervised embedding}},
  booktitle = {Proc. 25th Int. Conf. Mach. Learn.},
  year = {2008},
  pages = {1168--1175},
  abstract = {We show how nonlinear embedding algorithms popular for use with shallow
	semi-supervised learning techniques such as kernel methods can be
	applied to deep multilayer architectures, either as a regularizer
	at the output layer, or on each layer of the architecture. This provides
	a simple alternative to existing approaches to deep learning whilst
	yielding competitive error rates compared to those methods, and existing
	shallow semi-supervised techniques. Copyright 2008 by the author(s)/owner(s).},
  isbn = {9781605582054},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449119888&partnerID=tZOtx3y1}
}

@ARTICLE{Williams2006,
  author = {Williams, CKI and Rasmussen, CE},
  title = {{Gaussian processes for machine learning}},
  journal = {MIT Press},
  year = {2006},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Williams, Rasmussen_2006_Gaussian processes for machine learning.pdf:pdf},
  url = {http://www-old.newton.ac.uk/programmes/BNR/seminars/2007080914001.pdf}
}

@INPROCEEDINGS{Xue2008,
  author = {Xue, Gui-Rong and Xing, Dikan and Yang, Qiang and Yu, Yong},
  title = {{Deep classification in large-scale text hierarchies}},
  booktitle = {Proc. 31st Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. - SIGIR
	'08},
  year = {2008},
  pages = {619},
  address = {New York, New York, USA},
  publisher = {ACM Press},
  abstract = {Most classification algorithms are best at categorizing the Web documents
	into a few categories, such as the top two levels in the Open Directory
	Project. Such a classification method does not give very detailed
	topic-related class information for the user because the first two
	levels are often too coarse. However, classification on a large-scale
	hierarchy is known to be intractable for many target categories with
	cross-link relationships among them. In this paper, we propose a
	novel deep-classification approach to categorize Web documents into
	categories in a large-scale taxonomy. The approach consists of two
	stages: a search stage and a classification stage. In the first stage,
	a category-search algorithm is used to acquire the category candidates
	for a given document. Based on the category candidates, we prune
	the large-scale hierarchy to focus our classification effort on a
	small subset of the original hierarchy. As a result, the classification
	model is trained on the small subset before being applied to assign
	the category for a new document. Since the category candidates are
	sufficiently close to each other in the hierarchy, a statistical-language-model
	based classifier using n-gram features is exploited. Furthermore,
	the structure of the taxonomy can be utilized in this stage to improve
	the performance of classification. We demonstrate the performance
	of our proposed algorithms on the Open Directory Project with, over
	130,000 categories. Experimental results show that our proposed approach
	can reach 51.8% on the measure of Mi-Fl at the 5th level, which is
	77.7% improvement over top-down based SVM classification algorithms.
	Copyright 2008 ACM.},
  doi = {10.1145/1390334.1390440},
  isbn = {9781605581644},
  keywords = {Deep classification,Hierarchical classification,Large scale hierarchy},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349177558&partnerID=tZOtx3y1}
}

@ARTICLE{Lecun1995,
  author = {{Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes,
	John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard},
	Vladimir Vapnik},
  title = {{Learning Algorithms For Classification: A Comparison On Handwritten
	Digit Recognition}},
  journal = {Neural Networks Stat. Mech. Perspect.},
  year = {1995},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes, John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard_1.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.4628}
}

@BOOK{Yin2008,
  title = {{The self-organizing maps: background, theories, extensions and applications}},
  publisher = {Springer Berlin Heidelberg},
  year = {2008},
  editor = {Fulcher, John and Jain, L. C.},
  author = {Yin, Hujun},
  volume = {115},
  pages = {715--762},
  series = {Studies in Computational Intelligence},
  address = {Berlin, Heidelberg},
  abstract = {For many years, artificial neural networks (ANNs) have been studied
	and used to model information processing systems based on or inspired
	by biological neural structures. They not only can provide solutions
	with improved performance when compared with traditional problem-solving
	methods, but also give a deeper understanding of human cognitive
	abilities. Among various existing neural network architectures and
	learning algorithms, Kohonen's selforganizing map (SOM) [46] is one
	of the most popular neural network models. Developed for an associative
	memory model, it is an unsupervised learning algorithm with a simple
	structure and computational form, and is motivated by the retina-cortex
	mapping. Self-organization in general is a fundamental pattern recognition
	process, in which intrinsic inter- and intra-pattern relationships
	among the stimuli and responses are learnt without the presence of
	a potentially biased or subjective external influence. The SOM can
	provide topologically preserved mapping from input to output spaces.
	Although the computational form of the SOM is very simple, numerous
	researchers have already examined the algorithm and many of its problems,
	nevertheless research in this area goes deeper and deeper - there
	are still many aspects to be exploited. In this Chapter, we review
	the background, theories and statistical properties of this important
	learning model and present recent advances from various pattern recognition
	aspects through a number of case studies and applications. The SOM
	is optimal for vector quantization. Its topographical ordering provides
	the mapping with enhanced fault- and noise-tolerant abilities. It
	is also applicable to many other applications, such as dimensionality
	reduction, data visualization, clustering and classification. Various
	extensions of the SOM have been devised since its introduction to
	extend the mapping as effective solutions for a wide range of applications.
	Its connections with other learning paradigms and application aspects
	are also exploited. The Chapter is intended to serve as an updated,
	extended tutorial, a review, as well as a reference for advanced
	topics in the subject. © 2008 Springer-Verlag Berlin Heidelberg.},
  booktitle = {Comput. Intell. a Compend.},
  doi = {10.1007/978-3-540-78293-3},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yin_2008_The self-organizing maps background, theories, extensions and applications.pdf:pdf},
  isbn = {978-3-540-78292-6},
  issn = {1860949X},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44849094485&partnerID=tZOtx3y1}
}

@INPROCEEDINGS{Bengio2007a,
  author = {{Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e}
	De Montr\'{e}al}, Montr\'{e}al Qu\'{e}bec and Bengio, Yoshua and
	Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
  title = {{Greedy layer-wise training of deep networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2007},
  number = {19},
  pages = {153--160},
  abstract = {Complexity theory of circuits strongly suggests that deep architectures
	can be much more efficient (sometimes exponentially) than shallow
	architectures, in terms of computational elements required to represent
	some functions. Deep multi-layer neural networks have many levels
	of non-linearities allowing them to compactly represent highly non-linear
	and highly-varying functions. However, until recently it was not
	clear how to train such deep networks, since gradient-based optimization
	starting from random initialization appears to often get stuck in
	poor solutions. Hinton et al. recently introduced a greedy layer-wise
	unsupervised learning algorithm for Deep Belief Networks (DBN), a
	generative model with many layers of hidden causal variables. In
	the context of the above optimization problem, we study this algorithm
	empirically and explore variants to better understand its success
	and extend it to cases where the inputs are continuous or where the
	structure of the input distribution is not revealing enough about
	the variable to be predicted in a supervised task. Our experiments
	also confirm the hypothesis that the greedy layer-wise unsupervised
	training strategy mostly helps the optimization, by initializing
	weights in a region near a good local minimum, giving rise to internal
	distributed representations that are high-level abstractions of the
	input, bringing better generalization.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\\'{e} De Montr\\'{e}al et al._2007_Greedy layer-wise training of deep netw.pdf:pdf},
  isbn = {9780262195683},
  issn = {10495258},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864073449&partnerID=tZOtx3y1 http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.2022}
}

@ARTICLE{Yu2011,
  author = {Yu, Dong and Deng, Li},
  title = {{Deep Learning and Its Applications to Signal and Information Processing
	[Exploratory DSP}},
  journal = {IEEE Signal Process. Mag.},
  year = {2011},
  volume = {28},
  pages = {145--154},
  number = {1},
  month = {\#jan\#},
  abstract = {Today, signal processing research has a significantly widened its
	scope compared with just a few years ago [4], and machine learning
	has been an important technical area of the signal processing society.
	Since 2006, deep learninga new area of machine learning research
	has emerged [7], impacting a wide range of signal and information
	processing work within the traditional and the new, widened scopes.
	Various workshops, such as the 2009 ICML Workshop on Learning Feature
	Hierarchies; the 2008 NIPS Deep Learning Workshop: Foundations and
	Future Directions; and the 2009 NIPS Workshop on Deep Learning for
	Speech Recognition and Related Applications as well as an upcoming
	special issue on deep learning for speech and language processing
	in IEEE Transactions on Audio, Speech, and Language Processing (2010)
	have been devoted exclusively to deep learning and its applications
	to classical signal processing areas. We have also seen the government
	sponsor research on deep learning (e.g., the DARPA deep learning
	program, available at http://www.darpa.mil/ipto/solicit/baa/BAA-09-40-
	PIP.pdf). © 2010 IEEE.},
  doi = {10.1109/MSP.2010.939038},
  issn = {1053-5888},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650425762&partnerID=tZOtx3y1}
}

@ARTICLE{Zouaq2011,
  author = {Zouaq, Amal and Gasevic, Dragan and Hatala, Marek},
  title = {{Towards open ontology learning and filtering}},
  journal = {Inf. Syst.},
  year = {2011},
  volume = {36},
  pages = {1064--1081},
  number = {7},
  month = {\#nov\#},
  abstract = {Open ontology learning is the process of extracting a domain ontology
	from a knowledge source in an unsupervised way. Due to its unsupervised
	nature, it requires filtering mechanisms to rate the importance and
	correctness of the extracted knowledge. This paper presents OntoCmaps,
	a domain-independent and open ontology learning tool that extracts
	deep semantic representations from corpora. OntoCmaps generates rich
	conceptual representations in the form of concept maps and proposes
	an innovative filtering mechanism based on metrics from graph theory.
	Our results show that using metrics such as Betweenness, PageRank,
	Hits and Degree centrality outperforms the results of standard text-based
	metrics (TF-IDF, term frequency) for concept identification. We propose
	voting schemes based on these metrics that provide a good performance
	in relationship identification, which again provides better results
	(in terms of precision and F-measure) than other traditional metrics
	such as frequency of co-occurrences. The approach is evaluated against
	a gold standard and is compared to the ontology learning tool Text2Onto.
	The OntoCmaps generated ontology is more expressive than Text2Onto
	ontology especially in conceptual relationships and leads to better
	results in terms of precision, recall and F-measure. © 2011 Elsevier
	B.V.},
  doi = {10.1016/j.is.2011.03.005},
  issn = {03064379},
  keywords = {Filtering,Graph theory,Metrics,Ontology learning},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958101810&partnerID=tZOtx3y1}
}

