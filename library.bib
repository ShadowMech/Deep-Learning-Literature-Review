Automatically generated by Mendeley Desktop 1.13.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{YoshuaBengio,
author = {{Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e} De Montr\'{e}al}, Montr\'{e}al Qu\'{e}bec},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e} De Montr\'{e}al_2007_Greedy layer-wise training of deep networks.pdf:pdf},
journal = {Adv. Neural Inf. Process. Syst.},
keywords = {DBN},
mendeley-tags = {DBN},
number = {19},
pages = {153},
title = {{Greedy layer-wise training of deep networks}},
url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.2022},
year = {2007}
}
@inproceedings{Srivastava2012,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan R.},
booktitle = {Adv. Neural Inf. Process. Syst.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava, Salakhutdinov_2012_Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
keywords = {DBN},
mendeley-tags = {DBN},
pages = {2222--2230},
title = {{Multimodal Learning with Deep Boltzmann Machines}},
url = {http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines},
year = {2012}
}
@article{LeCun1998,
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
doi = {10.1109/5.726791},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1998_Gradient-based learning applied to document recognition.pdf:pdf},
issn = {00189219},
journal = {Proc. IEEE},
keywords = {2D shape variability,Character recognition,Feature extraction,GTN,Hidden Markov models,Machine learning,Multi-layer neural network,Neural networks,Optical character recognition software,Optical computing,Pattern recognition,Principal component analysis,back-propagation,backpropagation,cheque reading,complex decision surface synthesis,convolution,convolutional neural network character recognizers,document recognition,document recognition systems,field extraction,gradient based learning technique,gradient-based learning,graph transformer networks,handwritten character recognition,handwritten digit recognition task,high-dimensional patterns,language modeling,multilayer neural networks,multilayer perceptrons,multimodule systems,optical character recognition,performance measure minimization,segmentation recognition},
number = {11},
pages = {2278--2324},
shorttitle = {Proceedings of the IEEE},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=726791},
volume = {86},
year = {1998}
}
@article{Srivastava2014,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava et al._2014_Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
journal = {J. Mach. Learn. Res.},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
url = {http://jmlr.org/papers/v15/srivastava14a.html},
volume = {15},
year = {2014}
}
@article{QuocV.Le,
author = {{Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean}, Andrew Y. Ng},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean_2012_Building high-level features using large scale unsupe.pdf:pdf},
journal = {Int. Conf. Mach. Learn.},
title = {{Building high-level features using large scale unsupervised learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.261.605},
year = {2012}
}
@article{Lawrence1997,
abstract = {We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.},
author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
doi = {10.1109/72.554195},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lawrence et al._1997_Face recognition a convolutional neural-network approach.pdf:pdf},
issn = {1045-9227},
journal = {IEEE Trans. Neural Netw.},
keywords = {CNN,Face recognition,Feature extraction,Humans,Image databases,Image sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural networks,Quantization,Spatial databases,computational complexity,convolution,convolutional neural-network,dimensionality reduction,face recognition,feature extraction,image matching,invariance,local image sampling,quantisation (signal),quantization,self-organising feature maps,self-organizing map,template matching,topological space,topology},
mendeley-tags = {CNN},
month = jan,
number = {1},
pages = {98--113},
pmid = {18255614},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Face recognition: a convolutional neural-network approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614},
volume = {8},
year = {1997}
}
@article{Lecun1995,
author = {{Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes, John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard}, Vladimir Vapnik},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes, John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard_1.pdf:pdf},
journal = {Neural Networks Stat. Mech. Perspect.},
title = {{Learning Algorithms For Classification: A Comparison On Handwritten Digit Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.4628},
year = {1995}
}
@article{Mohamed2012,
abstract = {Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.},
author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
doi = {10.1109/TASL.2011.2109382},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton_2012_Acoustic Modeling Using Deep Belief Networks.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Trans. Audio. Speech. Lang. Processing},
keywords = {Acoustic modeling,Artificial neural networks,Computational modeling,DBN,Data models,Gaussian mixture models,Hidden Markov models,Speech,Speech recognition,TIMIT dataset,Training,acoustic modeling,backpropagation,belief networks,deep belief networks (DBNs),discriminative fine-tuning,emission distribution,hidden Markov models,monophone hidden Markov models,multilayer generative model,neural nets,neural networks,phone recognition,probability distribution,spectral feature vectors,speech recognition,statistical distributions},
mendeley-tags = {DBN},
month = jan,
number = {1},
pages = {14--22},
shorttitle = {Audio, Speech, and Language Processing, IEEE Trans},
title = {{Acoustic Modeling Using Deep Belief Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5704567},
volume = {20},
year = {2012}
}
@article{LeCun1998,
author = {LeCun, Yann and Bengio, Yoshua},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, Bengio_1998_Convolutional networks for images, speech, and time series.pdf:pdf},
isbn = {0-262-51102-9},
month = oct,
pages = {255--258},
publisher = {MIT Press},
title = {{Convolutional networks for images, speech, and time series}},
url = {http://dl.acm.org/citation.cfm?id=303568.303704},
year = {1998}
}
@inproceedings{Boureau2010,
abstract = {Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures.},
author = {Boureau, Y-Lan and Bach, Francis and LeCun, Yann and Ponce, Jean},
booktitle = {2010 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
doi = {10.1109/CVPR.2010.5539963},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boureau et al._2010_Learning mid-level features for recognition.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Convolutional codes,Dictionaries,Feature extraction,Gabor filter responses,Gabor filters,Image classification,Image coding,Image representation,Layout,Object recognition,SIFT descriptors,Vector quantization,coding step,feature extraction,learning (artificial intelligence),low level descriptors,mid level features learning,object recognition,pointwise transformation,pooling step,sparse coding,vector quantisation,vector quantization},
month = jun,
pages = {2559--2566},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Learning mid-level features for recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539963},
year = {2010}
}
@article{Fukushima1980,
author = {Fukushima, Kunihiko},
doi = {10.1007/BF00344251},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_1980_Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in positio.pdf:pdf},
issn = {0340-1200},
journal = {Biol. Cybern.},
month = apr,
number = {4},
pages = {193--202},
title = {{Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position}},
url = {http://link.springer.com/10.1007/BF00344251},
volume = {36},
year = {1980}
}
@inproceedings{Ranzato2008,
author = {Ranzato, Marc'aurelio and Boureau, Y-lan and Cun, Yann L.},
booktitle = {Adv. Neural Inf. Process. Syst.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato, Boureau, Cun_2008_Sparse Feature Learning for Deep Belief Networks.pdf:pdf},
keywords = {DBN},
mendeley-tags = {DBN},
pages = {1185--1192},
title = {{Sparse Feature Learning for Deep Belief Networks}},
url = {http://papers.nips.cc/paper/3363-sparse-feature-learning-for-deep-belief-networks},
year = {2008}
}
@article{Arel2010,
author = {Arel, Itamar and Rose, DC and Karnowski, TP},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Arel, Rose, Karnowski_2010_Deep machine learning-a new frontier in artificial intelligence research.pdf:pdf},
journal = {Comput. Intell. \ldots},
number = {November},
pages = {13--18},
title = {{Deep machine learning-a new frontier in artificial intelligence research}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5605630},
year = {2010}
}
@article{Deng2013,
abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
author = {Deng, Li and Yu, Dong},
doi = {10.1136/bmj.319.7209.0a},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng, Yu_2013_Deep Learning Methods and Applications.pdf:pdf},
isbn = {9781405161251},
issn = {09598138},
journal = {Found. Trends Signal Process.},
pages = {197----387},
pmid = {10463930},
title = {{Deep Learning: Methods and Applications}},
volume = {7},
year = {2013}
}
@article{Hinton2006,
abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
author = {Hinton, G E and Salakhutdinov, R R},
doi = {10.1126/science.1127647},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Salakhutdinov_2006_Reducing the dimensionality of data with neural networks.pdf:pdf},
isbn = {3135786504},
issn = {0036-8075},
journal = {Science},
month = jul,
number = {5786},
pages = {504--507},
pmid = {16873662},
title = {{Reducing the dimensionality of data with neural networks.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746600649&partnerID=tZOtx3y1},
volume = {313},
year = {2006}
}
@inproceedings{Ngiam2011,
abstract = {Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned ifmultiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evalu- ate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our mod- els are validated on the CUAVE and AVLet- ters datasets on audio-visual speech classifi- cation, demonstrating best published visual speech classification on AVLetters and effec- tive shared representation learning.},
author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
booktitle = {Proc. 28th Int. Conf. Mach. Learn.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ngiam et al._2011_Multimodal Deep Learning.pdf:pdf},
pages = {689--696},
title = {{Multimodal Deep Learning}},
year = {2011}
}
@article{Bengio2013,
abstract = {Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling deep learning algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges.},
archivePrefix = {arXiv},
arxivId = {1305.0445},
author = {Bengio, Yoshua},
eprint = {1305.0445},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2013_Deep Learning of Representations Looking Forward.pdf:pdf},
month = may,
title = {{Deep Learning of Representations: Looking Forward}},
url = {http://arxiv.org/abs/1305.0445},
year = {2013}
}
@article{Garcia2002,
abstract = { In this paper, we present a connectionist approach for detecting and precisely localizing semi-frontal human faces in complex images, making no assumption about the content or the lighting conditions of the scene, or about the size or the appearance of the faces. We propose a convolutional neural network architecture designed to recognize strongly variable face patterns directly from pixel images with no preprocessing, by automatically synthesizing its own set of feature extractors from a large training set of faces. We present in details the optimized design of our architecture, our learning strategy and the resulting process of face detection. We also provide experimental results to demonstrate the robustness of our approach and its capability to precisely detect extremely variable faces in uncontrolled environments.},
author = {Garcia, C and Delakis, M},
doi = {10.1109/ICPR.2002.1048232},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Garcia, Delakis_2002_A neural architecture for fast and robust face detection.pdf:pdf},
issn = {1051-4651},
journal = {Pattern Recognition, 2002. Proceedings. 16th Int. Conf.},
keywords = {automatic synthesis; complex images; connectionist},
number = {11},
pages = {44 -- 47 vol.2},
title = {{A neural architecture for fast and robust face detection}},
volume = {2},
year = {2002}
}
@article{Vincent2010,
author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2010_Stacked Denoising Autoencoders Learning Useful Representations in a Deep Network with a Local Denoising Criterion.pdf:pdf},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {3371--3408},
publisher = {JMLR.org},
title = {{Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1953039},
volume = {11},
year = {2010}
}
@article{Fukushima2003,
abstract = {The author previously proposed a neural network model neocognitron for robust visual pattern recognition. This paper proposes an improved version of the neocognitron and demonstrates its ability using a large database of handwritten digits (ETL1). To improve the recognition rate of the neocognitron, several modifications have been applied: such as, the inhibitory surround in the connections from S-cells to C-cells, contrast-extracting layer between input and edge-extracting layers, self-organization of line-extracting cells, supervised competitive learning at the highest stage, staggered arrangement of S- and C-cells, and so on. These modifications allowed the removal of accessory circuits that were appended to the previous versions, resulting in an improvement of recognition rate as well as simplification of the network architecture. The recognition rate varies depending on the number of training patterns. When we used 3000 digits (300 patterns for each digit) for the learning, for example, the recognition rate was 98.6% for a blind test set (3000 digits), and 100% for the training set.},
author = {Fukushima, Kunihiko},
doi = {10.1016/S0925-2312(02)00614-8},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_2003_Neocognitron for handwritten digit recognition.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Handwritten digit,Multi-layered network,Neocognitron,Neural network model,Visual pattern recognition},
month = apr,
pages = {161--180},
title = {{Neocognitron for handwritten digit recognition}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231202006148},
volume = {51},
year = {2003}
}
@article{Egmont-Petersen2002,
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments.},
author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
doi = {10.1016/S0031-3203(01)00178-9},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels_2002_Image processing with neural networks—a review.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognit.},
keywords = {Digital image processing,Feature extraction,Image compression,Image understanding,Invariant pattern recognition,Neural networks,Object recognition,Optimization,Preprocessing,Segmentation},
month = oct,
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks—a review}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789},
volume = {35},
year = {2002}
}
@inproceedings{Lee2009b,
address = {New York, New York, USA},
author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
booktitle = {Proc. 26th Annu. Int. Conf. Mach. Learn. - ICML '09},
doi = {10.1145/1553374.1553453},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations.pdf:pdf},
isbn = {9781605585161},
month = jun,
pages = {1--8},
publisher = {ACM Press},
title = {{Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations}},
url = {http://dl.acm.org/citation.cfm?id=1553374.1553453},
year = {2009}
}
@inproceedings{Salakhutdinov2007a,
address = {New York, New York, USA},
author = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
booktitle = {Proc. 24th Int. Conf. Mach. Learn. - ICML '07},
doi = {10.1145/1273496.1273596},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Mnih, Hinton_2007_Restricted Boltzmann machines for collaborative filtering.pdf:pdf},
isbn = {9781595937933},
keywords = {DBN},
mendeley-tags = {DBN},
month = jun,
pages = {791--798},
publisher = {ACM Press},
title = {{Restricted Boltzmann machines for collaborative filtering}},
url = {http://dl.acm.org/citation.cfm?id=1273496.1273596},
year = {2007}
}
@article{Lehman2014,
abstract = {Artificial intelligence (AI) is a sprawling field encompassing a diversity of approaches to machine intelligence and disparate perspectives on how intelligence should be viewed. Because researchers often engage only within their own specialized area of AI, there are many interesting broad questions about AI as a whole that often go unanswered. How should intelligence be abstracted in AI research? Which subfields, techniques, and abstractions are most promising? Why do researchers bet their careers on the particular abstractions and techniques of their chosen subfield of AI? Should AI research be "bio-inspired" and remain faithful to the process that produced intelligence (evolution) or the biological substrate that enables it (networks of neurons)? Discussing these big-picture questions motivated us to organize an AAAI Fall Symposium, which gathered participants across AI subfields to present and debate their views. This article distills the resulting insights.},
author = {Lehman, Joel and Clune, Jeff and Risi, Sebastian},
doi = {10.1109/MIS.2014.92},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lehman, Clune, Risi_2014_An Anarchy of Methods Current Trends in How Intelligence Is Abstracted in AI.pdf:pdf},
issn = {1541-1672},
journal = {IEEE Intell. Syst.},
keywords = {AI,AI abstraction,AI research,AI subfields,AI techniques,Adaptive systems,Artificial intelligence,Biological system modeling,Brain modeling,Computational modeling,Design methodology,Neural networks,Neuroscience,Robots,adaptive systems,artificial intelligence,bio-inspired research,cognitive science,computational neuroscience,deep learning,design automation,developmental robotics,evolving neural networks,intelligent systems,machine intelligence,neuroevolution},
month = nov,
number = {6},
pages = {56--62},
shorttitle = {Intelligent Systems, IEEE},
title = {{An Anarchy of Methods: Current Trends in How Intelligence Is Abstracted in AI}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6982117},
volume = {29},
year = {2014}
}
@article{Schmidhuber2014,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, Juergen},
eprint = {1404.7828},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Schmidhuber_2014_Deep Learning in Neural Networks An Overview.pdf:pdf},
month = apr,
pages = {75},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://arxiv.org/abs/1404.7828},
year = {2014}
}
@article{LeCun1990,
author = {{LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard}, L. D. Jackel},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard_1990_Handwritten Digit Recognition with a Back-Propagation Network.pdf:pdf},
journal = {Adv. Neural Inf. Process. Syst.},
pages = {396--404},
title = {{Handwritten Digit Recognition with a Back-Propagation Network}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076},
year = {1990}
}
@article{Ji2013,
abstract = {We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.},
author = {Ji, Shuiwang and Yang, Ming and Yu, Kai},
doi = {10.1109/TPAMI.2012.59},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ji, Yang, Yu_2013_3D convolutional neural networks for human action recognition.pdf:pdf},
issn = {1939-3539},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Decision Support Techniques,Image Interpretation,Imaging,Movement,Movement: physiology,Neural Networks (Computer),Pattern Recognition,Subtraction Technique,Three-Dimensional,Three-Dimensional: methods},
month = jan,
number = {1},
pages = {221--31},
pmid = {22392705},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{3D convolutional neural networks for human action recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22392705},
volume = {35},
year = {2013}
}
@article{Erhan2010,
abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v1},
author = {Erhan, Dumitru and Courville, Aaron and Vincent, Pascal and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
eprint = {arXiv:1206.5538v1},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Erhan et al._2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:pdf},
issn = {15324435},
journal = {J. Mach. Learn. Res.},
keywords = {AutoEnc,GenDL,Unsupervised,deep architectures,deep belief networks,non-convex optimization,stacked denoising auto-encoders,unsupervised pre-training},
mendeley-tags = {AutoEnc,GenDL,Unsupervised},
month = mar,
pages = {625--660},
publisher = {JMLR.org},
title = {{Why Does Unsupervised Pre-training Help Deep Learning ?}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1756025 http://portal.acm.org/citation.cfm?id=1756025},
volume = {11},
year = {2010}
}
@article{Salakhutdinov2009a,
abstract = {We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs “semantic hashing”: Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set.},
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
doi = {10.1016/j.ijar.2008.11.006},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Hinton_2009_Semantic hashing.pdf:pdf},
issn = {0888613X},
journal = {Int. J. Approx. Reason.},
keywords = {Graphical models,Information retrieval,Unsupervised learning},
month = jul,
number = {7},
pages = {969--978},
title = {{Semantic hashing}},
url = {http://www.sciencedirect.com/science/article/pii/S0888613X08001813},
volume = {50},
year = {2009}
}
@article{Marinai2005,
abstract = {Artificial neural networks have been extensively applied to document analysis and recognition. Most efforts have been devoted to the recognition of isolated handwritten and printed characters with widely recognized successful results. However, many other document processing tasks, like preprocessing, layout analysis, character segmentation, word recognition, and signature verification, have been effectively faced with very promising results. This paper surveys the most significant problems in the area of offline document image processing, where connectionist-based approaches have been applied. Similarities and differences between approaches belonging to different categories are discussed. A particular emphasis is given on the crucial role of prior knowledge for the conception of both appropriate architectures and learning algorithms. Finally, the paper provides a critical analysis on the reviewed approaches and depicts the most promising research guidelines in the field. In particular, a second generation of connectionist-based models are foreseen which are based on appropriate graphical representations of the learning environment.},
author = {Marinai, Simone and Gori, Marco and Soda, Giovanni and Society, Computer},
doi = {10.1109/TPAMI.2005.4},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Marinai et al._2005_Artificial neural networks for document analysis and recognition.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Automatic Data Processing,Automatic Data Processing: methods,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Documentation,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Neural Networks (Computer),Numerical Analysis,Pattern Recognition,Reading,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,User-Computer Interface},
month = jan,
number = {1},
pages = {23--35},
pmid = {15628266},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Artificial neural networks for document analysis and recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15628266},
volume = {27},
year = {2005}
}
@article{Bengio2007,
author = {Bengio, Yoshua and LeCun, Y},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, LeCun_2007_Scaling learning algorithms towards AI.pdf:pdf},
journal = {Large-scale kernel Mach.},
number = {1},
pages = {1--41},
title = {{Scaling learning algorithms towards AI}},
url = {http://www.iro.umontreal.ca/$\sim$lisa/bib/pub_subject/language/pointeurs/bengio+lecun-chapter2007.pdf},
year = {2007}
}
@inproceedings{Krizhevsky2012,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
booktitle = {Adv. Neural Inf. Process. Syst.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
keywords = {CNN},
mendeley-tags = {CNN},
pages = {1097--1105},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional},
year = {2012}
}
@inproceedings{Simard2003,
abstract = {Not Available},
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
booktitle = {Seventh Int. Conf. Doc. Anal. Recognition, 2003. Proceedings.},
doi = {10.1109/ICDAR.2003.1227801},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Simard, Steinkraus, Platt_2003_Best practices for convolutional neural networks applied to visual document analysis.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = {Best practices,CNN,Concrete,Convolution,Handwriting recognition,Industrial training,Information processing,Neural networks,Performance analysis,Support vector machines,Text analysis},
mendeley-tags = {CNN},
pages = {958--963},
publisher = {IEEE Comput. Soc},
shorttitle = {Document Analysis and Recognition, 2003. Proceedin},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801},
volume = {1},
year = {2003}
}
@article{Hinton2006a,
abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
annote = {Citations: 1274},
author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
doi = {10.1162/neco.2006.18.7.1527},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Osindero, Teh_2006_A fast learning algorithm for deep belief nets.pdf:pdf},
issn = {0899-7667},
journal = {Neural Comput.},
keywords = {Algorithms,Animals,DBN,Humans,Learning,Learning: physiology,Neural Networks (Computer),Neurons,Neurons: physiology},
mendeley-tags = {DBN},
month = jul,
number = {7},
pages = {1527--54},
pmid = {16764513},
shorttitle = {Neural Computation},
title = {{A fast learning algorithm for deep belief nets.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513},
volume = {18},
year = {2006}
}
@article{Bengio2009,
author = {Bengio, Yoshua},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2009_Learning deep architectures for AI.pdf:pdf},
journal = {Found. trends® Mach. Learn.},
title = {{Learning deep architectures for AI}},
url = {http://dl.acm.org/citation.cfm?id=1658424},
year = {2009}
}
@inproceedings{Lee2009,
author = {Lee, Honglak and Pham, Peter and Largman, Yan and Ng, Andrew Y.},
booktitle = {Adv. Neural Inf. Process. Syst.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised feature learning for audio classification using convolutional deep belief networks.pdf:pdf},
keywords = {CNN,Sound,Unsupervised},
mendeley-tags = {CNN,Sound,Unsupervised},
pages = {1096--1104},
title = {{Unsupervised feature learning for audio classification using convolutional deep belief networks}},
url = {http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for},
year = {2009}
}
@article{Bengio2012,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
archivePrefix = {arXiv},
arxivId = {1206.5538},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {10.1109/TPAMI.2013.50},
eprint = {1206.5538},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, Courville, Vincent_2012_Representation Learning A Review and New Perspectives.pdf:pdf},
issn = {1939-3539},
journal = {PAMI},
month = jun,
number = {1993},
pages = {1--30},
pmid = {23787338},
title = {{Representation Learning: A Review and New Perspectives}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23787338 http://arxiv.org/abs/1206.5538},
volume = {35},
year = {2012}
}
@article{LeCun1989,
abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
doi = {10.1162/neco.1989.1.4.541},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1989_Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
issn = {0899-7667},
journal = {Neural Comput.},
keywords = {CNN},
language = {en},
mendeley-tags = {CNN},
month = dec,
number = {4},
pages = {541--551},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541#.VOiy7DTkdNo},
volume = {1},
year = {1989}
}
@article{G.E.Hinton,
annote = {The latest idea of Hinton around computer vision},
author = {{G. E. Hinton, A. Krizhevsky}, S. D. Wang},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/G. E. Hinton, A. Krizhevsky_2011_Transforming Auto-encoders.pdf:pdf},
journal = {Artif. Neural Networks Mach. Learn. 2011.},
keywords = {Vision},
mendeley-tags = {Vision},
pages = {44--51.},
title = {{Transforming Auto-encoders}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.220.5099},
year = {2011}
}
